#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„ç›¸æœºå†…å‚æ ‡å®šè„šæœ¬
=======================
é’ˆå¯¹PnPç²¾åº¦é—®é¢˜çš„ä¼˜åŒ–æªæ–½:
1. å¢åŠ æ ‡å®šå›¾åƒè´¨é‡æ£€æŸ¥
2. è®¡ç®—è¯¦ç»†çš„é‡æŠ•å½±è¯¯å·®åˆ†æ
3. æ£€æµ‹å›¾åƒå§¿æ€å¤šæ ·æ€§
4. æä¾›æ ‡å®šè´¨é‡è¯„ä¼°æŠ¥å‘Š
5. æ”¯æŒå¤šç§æ£‹ç›˜æ ¼ç±»å‹

ä½¿ç”¨æ–¹æ³•:
  python calibrate_camera_improved.py --capture   # å®æ—¶æ‹ç…§é‡‡é›†
  python calibrate_camera_improved.py --calibrate # ä½¿ç”¨å·²æœ‰å›¾åƒæ ‡å®š
  python calibrate_camera_improved.py --all       # é‡‡é›†+æ ‡å®š
"""

import cv2
import numpy as np
import glob
import os
import argparse
from datetime import datetime
from scipy.spatial.transform import Rotation as R


class CameraCalibrator:
    """æ”¹è¿›çš„ç›¸æœºæ ‡å®šå™¨"""
    
    def __init__(self, 
                 board_size=(11, 8),
                 square_size=0.02073,  # 20.73mm
                 image_folder="./calib_images_right"):
        """
        Parameters
        ----------
        board_size : tuple
            æ£‹ç›˜æ ¼å†…è§’ç‚¹æ•° (åˆ—, è¡Œ)
        square_size : float
            æ£‹ç›˜æ ¼æ–¹æ ¼è¾¹é•¿ (å•ä½: ç±³)
        image_folder : str
            æ ‡å®šå›¾åƒå­˜æ”¾æ–‡ä»¶å¤¹ (å¦‚æœæ˜¯é‡‡é›†æ¨¡å¼ï¼Œå°†ä½œä¸ºæ ¹ç›®å½•åˆ›å»ºä¼šè¯å­ç›®å½•)
        """
        self.board_size = board_size
        self.square_size = square_size
        self.image_folder = image_folder
        
        # é»˜è®¤è¾“å‡ºå‰ç¼€ (å°†åœ¨ capture_images ä¸­æ›´æ–°ï¼Œæˆ–åœ¨ calibrate ä¸­ä½¿ç”¨å½“å‰ image_folder)
        self.output_prefix = os.path.join(image_folder, "camera_intrinsics")
        
        # æ„é€ ä¸–ç•Œåæ ‡ç‚¹
        self.objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)
        self.objp[:, :2] = np.mgrid[0:board_size[0], 0:board_size[1]].T.reshape(-1, 2)
        self.objp *= square_size
        
        # å­˜å‚¨æ ‡å®šæ•°æ®
        self.objpoints = []
        self.imgpoints = []
        self.image_files = []
        self.image_size = None
        
        # æ ‡å®šç»“æœ
        self.K = None
        self.dist = None
        self.rvecs = None
        self.tvecs = None
        self.reprojection_errors = []
        
        print("="*70)
        print("ğŸ“· ç›¸æœºå†…å‚æ ‡å®šå·¥å…· (æ”¹è¿›ç‰ˆ)")
        print("="*70)
        print(f"\næ£‹ç›˜æ ¼å‚æ•°:")
        print(f"  å†…è§’ç‚¹: {board_size[0]} Ã— {board_size[1]}")
        print(f"  æ–¹æ ¼å¤§å°: {square_size*1000:.1f} mm")
        print(f"  æ£‹ç›˜ç‰©ç†å®½åº¦: {(board_size[0]-1)*square_size*1000:.1f} mm")
        print(f"  æ£‹ç›˜ç‰©ç†é«˜åº¦: {(board_size[1]-1)*square_size*1000:.1f} mm")
        print(f"\nå›¾åƒæ–‡ä»¶å¤¹: {os.path.abspath(image_folder)}")
        print("="*70 + "\n")
        
        # å¦‚æœä¸æ˜¯é‡‡é›†æ¨¡å¼ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(image_folder):
            try:
                os.makedirs(image_folder, exist_ok=True)
            except:
                pass
    
    def capture_images(self, cam_id=2, min_images=15, max_images=30):
        """
        äº¤äº’å¼é‡‡é›†æ ‡å®šå›¾åƒ
        
        æ”¹è¿›ç‚¹:
        1. è‡ªåŠ¨åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ä¼šè¯ç›®å½•
        2. å®æ—¶æ˜¾ç¤ºè§’ç‚¹æ£€æµ‹çŠ¶æ€
        3. æ£€æŸ¥å›¾åƒå§¿æ€å¤šæ ·æ€§
        """
        # åˆ›å»ºæœ¬æ¬¡é‡‡é›†çš„ä¼šè¯ç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = os.path.join(self.image_folder, f"session_{timestamp}")
        os.makedirs(session_dir, exist_ok=True)
        
        # æ›´æ–°å½“å‰å·¥ä½œçš„å›¾åƒç›®å½•å’Œè¾“å‡ºå‰ç¼€
        self.image_folder = session_dir
        self.output_prefix = os.path.join(session_dir, "camera_intrinsics")
        
        print(f"ğŸ“‚ åˆ›å»ºé‡‡é›†ä¼šè¯ç›®å½•: {session_dir}")
        
        cap = cv2.VideoCapture(cam_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€ç›¸æœº")
            return False
        
        print("ğŸ“¸ å¼€å§‹é‡‡é›†æ ‡å®šå›¾åƒ")
        print("="*70)
        print("\nğŸ“– é‡‡é›†æŒ‡å— (ç¡®ä¿æ ‡å®šç²¾åº¦çš„å…³é”®!):")
        print("  1. æ£‹ç›˜æ ¼åº”è¦†ç›–å›¾åƒçš„ä¸åŒåŒºåŸŸ (ä¸­å¿ƒã€å››è§’ã€è¾¹ç¼˜)")
        print("  2. å˜æ¢æ£‹ç›˜æ ¼çš„å€¾æ–œè§’åº¦ (è‡³å°‘ Â±30Â°)")
        print("  3. è°ƒæ•´æ£‹ç›˜æ ¼è·ç¦» (è¿‘ã€ä¸­ã€è¿œ)")
        print("  4. ä¿æŒæ£‹ç›˜æ ¼å®Œå…¨åœ¨è§†é‡å†…")
        print("  5. ç¡®ä¿å…‰çº¿å‡åŒ€ï¼Œé¿å…åå…‰")
        print(f"\n  å»ºè®®é‡‡é›† {min_images}-{max_images} å¼ å›¾åƒ")
        print("\nâŒ¨ï¸  å¿«æ·é”®: SPACE=æ‹ç…§, Q=é€€å‡º\n")
        
        captured_poses = []  # è®°å½•å·²é‡‡é›†çš„å§¿æ€
        count = 0
        
        while count < max_images:
            ret, frame = cap.read()
            if not ret:
                break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            display = frame.copy()
            
            # æ£€æµ‹æ£‹ç›˜æ ¼
            flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK
            found, corners = cv2.findChessboardCorners(gray, self.board_size, flags)
            
            if found:
                # äºšåƒç´ ç²¾åŒ–
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
                corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
                
                # ç»˜åˆ¶è§’ç‚¹
                cv2.drawChessboardCorners(display, self.board_size, corners, found)
                
                # è®¡ç®—æ£‹ç›˜æ ¼å§¿æ€ (ç”¨äºæ£€æŸ¥å¤šæ ·æ€§)
                success, rvec, tvec = cv2.solvePnP(
                    self.objp, corners, 
                    np.array([[800, 0, 640], [0, 800, 360], [0, 0, 1]], dtype=np.float32),
                    None
                )
                
                if success:
                    euler = R.from_rotvec(rvec.flatten()).as_euler('xyz', degrees=True)
                    distance = np.linalg.norm(tvec) * 1000
                    
                    # æ˜¾ç¤ºå½“å‰å§¿æ€
                    cv2.putText(display, f"Distance: {distance:.0f}mm", (10, 60),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    cv2.putText(display, f"Angle: {euler[0]:.0f}, {euler[1]:.0f}, {euler[2]:.0f}", (10, 90),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    # æ£€æŸ¥å§¿æ€æ˜¯å¦æ–°é¢–
                    is_novel = self._check_pose_novelty(captured_poses, rvec, tvec)
                    if not is_novel:
                        cv2.putText(display, "Pose similar to existing - try different angle!", (10, 120),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
                
                cv2.putText(display, "DETECTED - Press SPACE", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                cv2.putText(display, "NOT DETECTED", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # æ˜¾ç¤ºè¿›åº¦
            h, w = display.shape[:2]
            cv2.putText(display, f"Captured: {count}/{max_images} (min: {min_images})", 
                       (w-300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # æ˜¾ç¤ºåŒºåŸŸè¦†ç›–æç¤º
            self._draw_coverage_guide(display, captured_poses)
            
            cv2.imshow('Camera Calibration', display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord(' ') and found:
                # ä¿å­˜å›¾åƒ
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = os.path.join(self.image_folder, f"calib_{count:02d}_{timestamp}.jpg")
                cv2.imwrite(filename, frame)
                
                # è®°å½•å§¿æ€
                captured_poses.append({
                    'rvec': rvec.copy() if success else None,
                    'tvec': tvec.copy() if success else None,
                    'corners': corners.copy()
                })
                
                count += 1
                print(f"âœ… å·²ä¿å­˜: {filename} ({count}/{max_images})")
        
        cap.release()
        cv2.destroyAllWindows()
        
        if count < min_images:
            print(f"\nâš ï¸  è­¦å‘Š: ä»…é‡‡é›† {count} å¼ å›¾åƒï¼Œå»ºè®®è‡³å°‘ {min_images} å¼ ")
        
        return count >= min_images
    
    def _check_pose_novelty(self, captured_poses, rvec, tvec, 
                            rot_threshold=15, trans_threshold=0.05):
        """æ£€æŸ¥å½“å‰å§¿æ€æ˜¯å¦ä¸å·²æœ‰å§¿æ€æœ‰è¶³å¤Ÿå·®å¼‚"""
        if not captured_poses:
            return True
        
        for pose in captured_poses:
            if pose['rvec'] is None:
                continue
            
            # æ—‹è½¬å·®å¼‚
            rot_diff = np.linalg.norm(rvec - pose['rvec'])
            rot_diff_deg = np.degrees(rot_diff)
            
            # å¹³ç§»å·®å¼‚
            trans_diff = np.linalg.norm(tvec - pose['tvec'])
            
            if rot_diff_deg < rot_threshold and trans_diff < trans_threshold:
                return False
        
        return True
    
    def _draw_coverage_guide(self, display, captured_poses):
        """ç»˜åˆ¶å›¾åƒåŒºåŸŸè¦†ç›–å¼•å¯¼"""
        h, w = display.shape[:2]
        
        # å°†å›¾åƒåˆ†æˆ 3x3 åŒºåŸŸ
        regions = np.zeros((3, 3), dtype=bool)
        
        for pose in captured_poses:
            if pose['corners'] is not None:
                center = np.mean(pose['corners'], axis=0)[0]
                col = int(center[0] / (w / 3))
                row = int(center[1] / (h / 3))
                col = min(2, max(0, col))
                row = min(2, max(0, row))
                regions[row, col] = True
        
        # ç»˜åˆ¶åŒºåŸŸç½‘æ ¼
        cell_w, cell_h = w // 3, h // 3
        for i in range(3):
            for j in range(3):
                x, y = j * cell_w, i * cell_h
                color = (0, 255, 0) if regions[i, j] else (0, 0, 255)
                cv2.rectangle(display, (x+2, y+2), (x+cell_w-2, y+cell_h-2), color, 1)
        
        # ç»Ÿè®¡è¦†ç›–ç‡
        coverage = np.sum(regions) / 9 * 100
        cv2.putText(display, f"Coverage: {coverage:.0f}%", (w-150, h-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def load_images(self):
        """åŠ è½½æ ‡å®šå›¾åƒå¹¶æ£€æµ‹è§’ç‚¹"""
        images = sorted(glob.glob(os.path.join(self.image_folder, "*.jpg")) +
                       glob.glob(os.path.join(self.image_folder, "*.png")))
        
        if not images:
            print(f"âŒ æœªæ‰¾åˆ°æ ‡å®šå›¾åƒ: {self.image_folder}")
            return False
        
        print(f"ğŸ“ æ‰¾åˆ° {len(images)} å¼ æ ‡å®šå›¾åƒ")
        
        self.objpoints = []
        self.imgpoints = []
        self.image_files = []
        
        for fname in images:
            img = cv2.imread(fname)
            if img is None:
                print(f"  âš ï¸ æ— æ³•è¯»å–: {fname}")
                continue
            
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            if self.image_size is None:
                self.image_size = gray.shape[::-1]
            
            # æ£€æµ‹è§’ç‚¹
            flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE
            found, corners = cv2.findChessboardCorners(gray, self.board_size, flags)
            
            if found:
                # äºšåƒç´ ç²¾åŒ– (å…³é”®æ­¥éª¤!)
                criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.0001)
                corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
                
                self.objpoints.append(self.objp)
                self.imgpoints.append(corners)
                self.image_files.append(fname)
                print(f"  âœ… {os.path.basename(fname)}")
            else:
                print(f"  âŒ æœªæ£€æµ‹åˆ°è§’ç‚¹: {os.path.basename(fname)}")
        
        print(f"\næˆåŠŸæ£€æµ‹ {len(self.imgpoints)}/{len(images)} å¼ å›¾åƒ")
        return len(self.imgpoints) >= 3
    
    def calibrate(self):
        """æ‰§è¡Œç›¸æœºæ ‡å®š"""
        if not self.imgpoints:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ ‡å®šæ•°æ®")
            return False
        
        print("\nğŸ“· å¼€å§‹ç›¸æœºæ ‡å®š...")
        print("-"*70)
        
        # ä½¿ç”¨æ”¹è¿›çš„æ ‡å®šå‚æ•°
        flags = 0
        # å¯é€‰: å›ºå®šæŸäº›å‚æ•°
        # flags |= cv2.CALIB_FIX_ASPECT_RATIO  # å›ºå®šçºµæ¨ªæ¯”
        # flags |= cv2.CALIB_ZERO_TANGENT_DIST  # å¿½ç•¥åˆ‡å‘ç•¸å˜
        # flags |= cv2.CALIB_FIX_K3  # å›ºå®š k3
        
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-6)
        
        ret, self.K, self.dist, self.rvecs, self.tvecs = cv2.calibrateCamera(
            self.objpoints, self.imgpoints, self.image_size, 
            None, None, flags=flags, criteria=criteria
        )
        
        print(f"\nâœ… æ ‡å®šå®Œæˆ!")
        print(f"\nå†…å‚çŸ©é˜µ K:")
        print(f"  fx = {self.K[0,0]:.2f}")
        print(f"  fy = {self.K[1,1]:.2f}")
        print(f"  cx = {self.K[0,2]:.2f}")
        print(f"  cy = {self.K[1,2]:.2f}")
        
        print(f"\nç•¸å˜ç³»æ•°:")
        print(f"  k1 = {self.dist[0,0]:.6f}")
        print(f"  k2 = {self.dist[0,1]:.6f}")
        print(f"  p1 = {self.dist[0,2]:.6f}")
        print(f"  p2 = {self.dist[0,3]:.6f}")
        print(f"  k3 = {self.dist[0,4]:.6f}")
        
        return True
    
    def evaluate_calibration(self):
        """è¯¦ç»†è¯„ä¼°æ ‡å®šè´¨é‡"""
        if self.K is None:
            print("âŒ è¯·å…ˆæ‰§è¡Œæ ‡å®š")
            return
        
        print("\nğŸ“Š æ ‡å®šè´¨é‡è¯„ä¼°")
        print("="*70)
        
        # 1. è®¡ç®—æ¯å¼ å›¾åƒçš„é‡æŠ•å½±è¯¯å·®
        total_error = 0
        self.reprojection_errors = []
        per_image_errors = []
        
        for i in range(len(self.objpoints)):
            imgpoints_proj, _ = cv2.projectPoints(
                self.objpoints[i], self.rvecs[i], self.tvecs[i], self.K, self.dist
            )
            error = cv2.norm(self.imgpoints[i], imgpoints_proj, cv2.NORM_L2) / len(imgpoints_proj)
            per_image_errors.append(error)
            total_error += error
            self.reprojection_errors.append({
                'image': self.image_files[i] if i < len(self.image_files) else f"Image {i}",
                'error': error
            })
        
        mean_error = total_error / len(self.objpoints)
        
        print(f"\nğŸ“ é‡æŠ•å½±è¯¯å·® (åƒç´ ):")
        print(f"   å¹³å‡è¯¯å·®: {mean_error:.4f}")
        print(f"   æœ€å¤§è¯¯å·®: {max(per_image_errors):.4f}")
        print(f"   æœ€å°è¯¯å·®: {min(per_image_errors):.4f}")
        print(f"   æ ‡å‡†å·®:   {np.std(per_image_errors):.4f}")
        
        # è´¨é‡è¯„çº§
        if mean_error < 0.3:
            quality = "ä¼˜ç§€ â­â­â­"
        elif mean_error < 0.5:
            quality = "è‰¯å¥½ â­â­"
        elif mean_error < 1.0:
            quality = "ä¸€èˆ¬ â­"
        else:
            quality = "è¾ƒå·® âš ï¸"
        
        print(f"\n   è´¨é‡è¯„çº§: {quality}")
        
        # 2. åˆ†æç•¸å˜ç¨‹åº¦
        print(f"\nğŸ“ ç•¸å˜åˆ†æ:")
        k1 = self.dist[0,0]
        if abs(k1) > 0.3:
            print(f"   âš ï¸ å¾„å‘ç•¸å˜è¾ƒå¤§ (k1={k1:.4f})ï¼Œå»ºè®®ä½¿ç”¨å»ç•¸å˜åçš„å›¾åƒ")
        elif abs(k1) > 0.1:
            print(f"   ä¸­ç­‰å¾„å‘ç•¸å˜ (k1={k1:.4f})")
        else:
            print(f"   å¾„å‘ç•¸å˜è¾ƒå° (k1={k1:.4f})")
        
        # 3. æ£€æŸ¥ç„¦è·ä¸€è‡´æ€§
        fx, fy = self.K[0,0], self.K[1,1]
        aspect_ratio = fx / fy
        print(f"\nğŸ“ ç„¦è·åˆ†æ:")
        print(f"   fx/fy æ¯”å€¼: {aspect_ratio:.4f}")
        if abs(aspect_ratio - 1.0) > 0.01:
            print(f"   âš ï¸ ç„¦è·ä¸å¯¹ç§°ï¼Œå¯èƒ½å­˜åœ¨ä¼ æ„Ÿå™¨éæ­£æ–¹å½¢åƒç´ æˆ–æ ‡å®šé—®é¢˜")
        
        # 4. æ£€æŸ¥ä¸»ç‚¹ä½ç½®
        cx, cy = self.K[0,2], self.K[1,2]
        img_center_x, img_center_y = self.image_size[0] / 2, self.image_size[1] / 2
        offset_x = abs(cx - img_center_x)
        offset_y = abs(cy - img_center_y)
        
        print(f"\nğŸ“ ä¸»ç‚¹åˆ†æ:")
        print(f"   ä¸»ç‚¹ä½ç½®: ({cx:.1f}, {cy:.1f})")
        print(f"   å›¾åƒä¸­å¿ƒ: ({img_center_x:.1f}, {img_center_y:.1f})")
        print(f"   åç§»é‡: ({offset_x:.1f}, {offset_y:.1f}) åƒç´ ")
        
        if offset_x > 50 or offset_y > 50:
            print(f"   âš ï¸ ä¸»ç‚¹åç¦»å›¾åƒä¸­å¿ƒè¾ƒè¿œï¼Œå¯èƒ½å½±å“ç²¾åº¦")
        
        # 5. åˆ—å‡ºè¯¯å·®æœ€å¤§çš„å›¾åƒ
        print(f"\nğŸ“‹ å„å›¾åƒé‡æŠ•å½±è¯¯å·®:")
        sorted_errors = sorted(self.reprojection_errors, key=lambda x: x['error'], reverse=True)
        for item in sorted_errors[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            status = "âš ï¸" if item['error'] > 0.5 else "âœ…"
            print(f"   {status} {os.path.basename(item['image'])}: {item['error']:.4f} px")
        
        # å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if mean_error > 0.5:
            print("   1. é‡æ–°é‡‡é›†æ ‡å®šå›¾åƒï¼Œç¡®ä¿è§’ç‚¹æ¸…æ™°")
            print("   2. å¢åŠ å›¾åƒæ•°é‡å’Œå§¿æ€å¤šæ ·æ€§")
            print("   3. æ£€æŸ¥æ£‹ç›˜æ ¼æ˜¯å¦å¹³æ•´")
        if abs(k1) > 0.3:
            print("   4. è€ƒè™‘ä½¿ç”¨æ›´é«˜é˜¶çš„ç•¸å˜æ¨¡å‹")
        
        return mean_error
    
    def save_results(self):
        """ä¿å­˜æ ‡å®šç»“æœ"""
        if self.K is None:
            print("âŒ æ²¡æœ‰æ ‡å®šç»“æœå¯ä¿å­˜")
            return
        
        # ä¿å­˜ OpenCV YAML æ ¼å¼ (å†…å‚)
        yaml_file = f"{self.output_prefix}.yaml"
        fs = cv2.FileStorage(yaml_file, cv2.FILE_STORAGE_WRITE)
        fs.write("K", self.K)
        fs.write("distCoeffs", self.dist)
        fs.write("image_width", self.image_size[0])
        fs.write("image_height", self.image_size[1])
        fs.write("board_size_cols", self.board_size[0])
        fs.write("board_size_rows", self.board_size[1])
        fs.write("square_size", self.square_size)
        fs.write("calibration_date", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        # è®¡ç®—å¹¶ä¿å­˜å¹³å‡é‡æŠ•å½±è¯¯å·®
        if self.reprojection_errors:
            errors = [e['error'] for e in self.reprojection_errors]
            fs.write("mean_reprojection_error", np.mean(errors))
        
        fs.release()
        print(f"\nğŸ’¾ å†…å‚å·²ä¿å­˜: {yaml_file}")
        
        # ä¿å­˜å¤–å‚åˆ°YAML (æ¯å¼ å›¾åƒçš„ T_target_cam)
        if self.rvecs is not None:
            extrinsic_yaml_file = os.path.join(self.image_folder, "extrinsics.yaml")
            fs_ext = cv2.FileStorage(extrinsic_yaml_file, cv2.FILE_STORAGE_WRITE)
            
            fs_ext.write("num_images", len(self.rvecs))
            fs_ext.write("board_size_cols", self.board_size[0])
            fs_ext.write("board_size_rows", self.board_size[1])
            fs_ext.write("square_size", self.square_size)
            
            extrinsics = []
            for i, (rvec, tvec) in enumerate(zip(self.rvecs, self.tvecs)):
                R_mat, _ = cv2.Rodrigues(rvec)
                T = np.eye(4)
                T[:3, :3] = R_mat
                T[:3, 3] = tvec.squeeze()
                extrinsics.append(T)
                
                # å†™å…¥æ¯ä¸ªå¤–å‚çŸ©é˜µ
                fs_ext.write(f"T_target_cam_{i}", T)
                fs_ext.write(f"rvec_{i}", rvec)
                fs_ext.write(f"tvec_{i}", tvec)
                
                # å†™å…¥å¯¹åº”çš„å›¾åƒæ–‡ä»¶å
                if i < len(self.image_files):
                    fs_ext.write(f"image_{i}", os.path.basename(self.image_files[i]))
            
            fs_ext.release()
            print(f"ğŸ’¾ å¤–å‚å·²ä¿å­˜ (YAML): {extrinsic_yaml_file}")
            
            # åŒæ—¶ä¿å­˜npyæ ¼å¼ä»¥å…¼å®¹æ—§ä»£ç 
            npy_file = os.path.join(self.image_folder, "extrinsics.npy")
            np.save(npy_file, np.array(extrinsics))
            print(f"ğŸ’¾ å¤–å‚å·²ä¿å­˜ (NPY): {npy_file}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = f"{self.output_prefix}_report.txt"
        with open(report_file, 'w') as f:
            f.write("="*70 + "\n")
            f.write("ç›¸æœºæ ‡å®šæŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*70 + "\n\n")
            
            f.write("æ£‹ç›˜æ ¼å‚æ•°:\n")
            f.write(f"  å†…è§’ç‚¹: {self.board_size[0]} Ã— {self.board_size[1]}\n")
            f.write(f"  æ–¹æ ¼å¤§å°: {self.square_size*1000:.1f} mm\n\n")
            
            f.write("å†…å‚çŸ©é˜µ K:\n")
            f.write(f"  [[{self.K[0,0]:.6f}, {self.K[0,1]:.6f}, {self.K[0,2]:.6f}],\n")
            f.write(f"   [{self.K[1,0]:.6f}, {self.K[1,1]:.6f}, {self.K[1,2]:.6f}],\n")
            f.write(f"   [{self.K[2,0]:.6f}, {self.K[2,1]:.6f}, {self.K[2,2]:.6f}]]\n\n")
            
            f.write("ç•¸å˜ç³»æ•°:\n")
            f.write(f"  k1={self.dist[0,0]:.8f}\n")
            f.write(f"  k2={self.dist[0,1]:.8f}\n")
            f.write(f"  p1={self.dist[0,2]:.8f}\n")
            f.write(f"  p2={self.dist[0,3]:.8f}\n")
            f.write(f"  k3={self.dist[0,4]:.8f}\n\n")
            
            if self.reprojection_errors:
                f.write("é‡æŠ•å½±è¯¯å·®:\n")
                for item in self.reprojection_errors:
                    f.write(f"  {os.path.basename(item['image'])}: {item['error']:.4f} px\n")
                errors = [e['error'] for e in self.reprojection_errors]
                f.write(f"\n  å¹³å‡: {np.mean(errors):.4f} px\n")
                f.write(f"  æ ‡å‡†å·®: {np.std(errors):.4f} px\n")
        
        print(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def undistort_test(self):
        """æµ‹è¯•å»ç•¸å˜æ•ˆæœ"""
        if self.K is None:
            print("âŒ è¯·å…ˆæ‰§è¡Œæ ‡å®š")
            return
        
        if not self.image_files:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•å›¾åƒ")
            return
        
        # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾åƒæµ‹è¯•
        img = cv2.imread(self.image_files[0])
        h, w = img.shape[:2]
        
        # è®¡ç®—æœ€ä¼˜æ–°ç›¸æœºçŸ©é˜µ
        new_K, roi = cv2.getOptimalNewCameraMatrix(self.K, self.dist, (w, h), 1, (w, h))
        
        # å»ç•¸å˜
        undistorted = cv2.undistort(img, self.K, self.dist, None, new_K)
        
        # è£å‰ªæœ‰æ•ˆåŒºåŸŸ
        x, y, roi_w, roi_h = roi
        if roi_w > 0 and roi_h > 0:
            undistorted_cropped = undistorted[y:y+roi_h, x:x+roi_w]
        else:
            undistorted_cropped = undistorted
        
        # æ˜¾ç¤ºå¯¹æ¯”
        comparison = np.hstack([
            cv2.resize(img, (640, 480)),
            cv2.resize(undistorted, (640, 480))
        ])
        
        cv2.putText(comparison, "Original", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(comparison, "Undistorted", (650, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        cv2.imshow('Undistortion Test', comparison)
        print("\nğŸ“· æ˜¾ç¤ºå»ç•¸å˜å¯¹æ¯”å›¾ï¼ŒæŒ‰ä»»æ„é”®ç»§ç»­...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        # ä¿å­˜å»ç•¸å˜å›¾åƒ
        save_path = os.path.join(self.image_folder, 'undistorted_test.jpg')
        cv2.imwrite(save_path, undistorted)
        print(f"ğŸ’¾ å»ç•¸å˜æµ‹è¯•å›¾åƒå·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='ç›¸æœºå†…å‚æ ‡å®šå·¥å…·')
    parser.add_argument('--capture',                                                action='store_true', help='é‡‡é›†æ ‡å®šå›¾åƒ')
    parser.add_argument('--calibrate', action='store_true', help='æ‰§è¡Œæ ‡å®š')
    parser.add_argument('--all', action='store_true', help='é‡‡é›†+æ ‡å®š')
    parser.add_argument('--camid', type=int, default=0, help='ç›¸æœºID')
    parser.add_argument('--image-folder', default='./calib_images_right', help='å›¾åƒæ–‡ä»¶å¤¹')
    
    args = parser.parse_args()
    
    calibrator = CameraCalibrator(
        image_folder=args.image_folder
    )
    
    if args.capture or args.all:
        calibrator.capture_images(cam_id=args.camid)
    
    if args.calibrate or args.all or (not args.capture and not args.all):
        if calibrator.load_images():
            if calibrator.calibrate():
                calibrator.evaluate_calibration()
                calibrator.save_results()
                calibrator.undistort_test()


if __name__ == '__main__':
    main()
