#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœ¼åœ¨æ‰‹ä¸Š (Eye-in-Hand) æ‰‹çœ¼æ ‡å®šè„šæœ¬
=====================================
åŠŸèƒ½:
  1. æ§åˆ¶æœºæ¢°è‡‚ç§»åŠ¨åˆ°ä¸åŒä½å§¿
  2. åœ¨æ¯ä¸ªä½å§¿é‡‡é›†å›¾åƒå¹¶æ£€æµ‹æ£‹ç›˜æ ¼
  3. ä½¿ç”¨PnPè®¡ç®—æ£‹ç›˜æ ¼åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„ä½å§¿ (T_target_cam)
  4. ä½¿ç”¨æ­£è¿åŠ¨å­¦è®¡ç®—æœ«ç«¯åœ¨åŸºåº§æ ‡ç³»ä¸‹çš„ä½å§¿ (T_gripper_base)
  5. ä½¿ç”¨Tsai-Lenzæ–¹æ³•æ±‚è§£æ‰‹çœ¼å˜æ¢çŸ©é˜µ (T_cam_gripper)

ä½¿ç”¨æ–¹æ³•:
  python handeye_calibration_eyeinhand.py --collect   # é‡‡é›†æ•°æ®
  python handeye_calibration_eyeinhand.py --calibrate # æ ‡å®šè®¡ç®—
  python handeye_calibration_eyeinhand.py --all       # é‡‡é›†+æ ‡å®š

åæ ‡ç³»å®šä¹‰:
  - base: æœºæ¢°è‡‚åŸºåº§åæ ‡ç³»
  - gripper/end-effector: æœºæ¢°è‡‚æœ«ç«¯åæ ‡ç³»
  - cam: ç›¸æœºåæ ‡ç³»
  - target: æ ‡å®šæ¿åæ ‡ç³»

çœ¼åœ¨æ‰‹ä¸Šæ–¹ç¨‹: AX = XB
  - A: ç›¸é‚»ä¸¤ä¸ªæœ«ç«¯ä½å§¿çš„ç›¸å¯¹å˜æ¢
  - B: ç›¸é‚»ä¸¤ä¸ªæ ‡å®šæ¿ä½å§¿çš„ç›¸å¯¹å˜æ¢  
  - X: ç›¸æœºç›¸å¯¹äºæœ«ç«¯çš„å˜æ¢ (T_cam_gripper)
"""

import os
import sys
import cv2
import glob
import numpy as np
import time
import argparse
import shutil
from datetime import datetime
from scipy.spatial.transform import Rotation as R

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from driver.ftservo_controller import ServoController
from ik.robot import create_so101_5dof_gripper
from handeye_utils import (
    evaluate_eye_in_hand_consistency,
    print_consistency_report,
)


class HandEyeCalibrator:
    """çœ¼åœ¨æ‰‹ä¸Šæ‰‹çœ¼æ ‡å®šå™¨"""

    def __init__(
        self,
        board_size=(11, 8),
        square_size=0.02073,
        intrinsic_file="camera_intrinsics.yaml",
        output_dir="./handeye_data",
    ):
        self.board_size = board_size
        self.square_size = square_size
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

        self.load_camera_intrinsics(intrinsic_file)

        self.objp = np.zeros((board_size[0] * board_size[1], 3), np.float32)
        self.objp[:, :2] = np.mgrid[0 : board_size[0], 0 : board_size[1]].T.reshape(-1, 2)
        self.objp *= square_size

        self.robot = None
        self.controller = None

        self.T_target_cam_list = []
        self.T_gripper_base_list = []
        self.images = []

        self.pose_buffer = []
        self.pose_buffer_size = 5

        print("=" * 70)
        print("ğŸ¤– çœ¼åœ¨æ‰‹ä¸Š (Eye-in-Hand) æ‰‹çœ¼æ ‡å®šå·¥å…·")
        print("=" * 70)
        print(f"\næ£‹ç›˜æ ¼å‚æ•°:")
        print(f"  å†…è§’ç‚¹: {board_size[0]} Ã— {board_size[1]}")
        print(f"  æ–¹æ ¼å¤§å°: {square_size * 1000:.2f} mm")
        print(f"\næ•°æ®ä¿å­˜ç›®å½•: {os.path.abspath(output_dir)}")
        print("=" * 70)

    # ------------------------------------------------------------------
    # å†…å‚åŠ è½½
    # ------------------------------------------------------------------
    def load_camera_intrinsics(self, yaml_path):
        if not os.path.exists(yaml_path):
            raise FileNotFoundError(f"æœªæ‰¾åˆ°ç›¸æœºå†…å‚æ–‡ä»¶: {yaml_path}")
        fs = cv2.FileStorage(yaml_path, cv2.FILE_STORAGE_READ)
        self.K = fs.getNode("K").mat()
        self.dist = fs.getNode("distCoeffs").mat().flatten()
        fs.release()
        print(f"\nğŸ“· å·²åŠ è½½ç›¸æœºå†…å‚: {yaml_path}")
        print(f"   fx={self.K[0,0]:.1f}, fy={self.K[1,1]:.1f}")
        print(f"   cx={self.K[0,2]:.1f}, cy={self.K[1,2]:.1f}")

    # ------------------------------------------------------------------
    # æœºå™¨äººåˆå§‹åŒ– & è¯»å–ä½å§¿
    # ------------------------------------------------------------------
    def init_robot(self, port="/dev/ttyACM0", baudrate=1_000_000):
        print("\nğŸ¤– åˆå§‹åŒ–æœºå™¨äºº...")
        self.controller = ServoController(
            port=port,
            baudrate=baudrate,
            config_path=os.path.join(os.path.dirname(__file__), "../driver/servo_config.json"),
        )
        self.robot = create_so101_5dof_gripper()
        self.robot.set_servo_controller(self.controller)
        print("âœ… æœºå™¨äººåˆå§‹åŒ–å®Œæˆ")
        return True

    def read_robot_pose(self, verbose=True):
        q = self.robot.read_joint_angles(joint_names=self.robot.joint_names, verbose=verbose)
        T_gripper_base = self.robot.fkine(q)
        if verbose:
            pos = T_gripper_base[:3, 3]
            euler = R.from_matrix(T_gripper_base[:3, :3]).as_euler("xyz", degrees=True)
            print(f"\nğŸ“ æœ«ç«¯ä½å§¿:")
            print(f"   ä½ç½®: x={pos[0]*1000:.1f}mm, y={pos[1]*1000:.1f}mm, z={pos[2]*1000:.1f}mm")
            print(f"   å§¿æ€: roll={euler[0]:.1f}Â°, pitch={euler[1]:.1f}Â°, yaw={euler[2]:.1f}Â°")
        return T_gripper_base, q

    # ------------------------------------------------------------------
    # æ£‹ç›˜æ ¼æ£€æµ‹ & PnP
    # ------------------------------------------------------------------
    def detect_chessboard(self, frame, use_ransac=True, refine_pose=True):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_FAST_CHECK
        found, corners = cv2.findChessboardCorners(gray, self.board_size, flags)
        if not found:
            return False, None, None, float("inf")

        criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5)
        corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        imgp = corners.reshape(-1, 2).astype(np.float32)

        if use_ransac:
            success, rvec, tvec, inliers = cv2.solvePnPRansac(
                self.objp, imgp, self.K, self.dist, iterationsCount=1000, reprojectionError=2.0
            )
            if inliers is not None and len(inliers) < len(self.objp) * 0.8:
                return False, None, corners, float("inf")
        else:
            success, rvec, tvec = cv2.solvePnP(self.objp, imgp, self.K, self.dist)

        if not success:
            return False, None, corners, float("inf")

        if refine_pose:
            rvec, tvec = cv2.solvePnPRefineLM(self.objp, imgp, self.K, self.dist, rvec, tvec)

        reproj, _ = cv2.projectPoints(self.objp, rvec, tvec, self.K, self.dist)
        reproj_error = np.sqrt(np.mean(np.sum((imgp - reproj.reshape(-1, 2)) ** 2, axis=1)))
        if reproj_error > 2.0:
            return False, None, corners, reproj_error

        Rmat, _ = cv2.Rodrigues(rvec)
        T = np.eye(4)
        T[:3, :3] = Rmat
        T[:3, 3] = tvec.squeeze()
        return True, T, corners, reproj_error

    # ------------------------------------------------------------------
    # ä½å§¿ç¼“å†² & å¹³å‡
    # ------------------------------------------------------------------
    def update_pose_buffer(self, T):
        self.pose_buffer.append(T.copy())
        if len(self.pose_buffer) > self.pose_buffer_size:
            self.pose_buffer.pop(0)

    def get_averaged_pose(self):
        if len(self.pose_buffer) < 3:
            return None
        translations = np.array([T[:3, 3] for T in self.pose_buffer])
        t_avg = np.mean(translations, axis=0)
        quats = np.array([R.from_matrix(T[:3, :3]).as_quat() for T in self.pose_buffer])
        q_avg = np.mean(quats, axis=0)
        q_avg /= np.linalg.norm(q_avg)
        R_avg = R.from_quat(q_avg).as_matrix()
        T_avg = np.eye(4)
        T_avg[:3, :3] = R_avg
        T_avg[:3, 3] = t_avg
        return T_avg

    # ------------------------------------------------------------------
    # äº¤äº’å¼é‡‡é›†
    # ------------------------------------------------------------------
    def collect_data_interactive(self, cam_id=0):
        cap = cv2.VideoCapture(cam_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€ç›¸æœº")
            return False

        print("\nğŸ“¸ å¼€å§‹äº¤äº’å¼æ•°æ®é‡‡é›†")
        print("=" * 70)
        print("   SPACE - é‡‡é›† | 'h' - å›ä¸­ | 's' - æ˜¾ç¤º/éšè—ç¨³å®šæ€§ | 'q' - é€€å‡º")
        print("=" * 70)

        sample_count = 0
        show_stability = True
        self.pose_buffer = []

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            display = frame.copy()
            success, T_target_cam, corners, reproj_error = self.detect_chessboard(frame)
            is_stable = False

            if success and corners is not None:
                cv2.drawChessboardCorners(display, self.board_size, corners, True)
                self.update_pose_buffer(T_target_cam)

                if len(self.pose_buffer) >= 3:
                    t_std = np.std([T[:3, 3] for T in self.pose_buffer], axis=0) * 1000
                    t_std_norm = np.linalg.norm(t_std)
                    is_stable = t_std_norm < 3.0 and reproj_error < 1.0
                    if show_stability:
                        cv2.putText(
                            display,
                            f"Std: {t_std_norm:.1f}mm, Err: {reproj_error:.2f}px",
                            (10, 90),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.6,
                            (255, 255, 255),
                            2,
                        )

                dist_mm = np.linalg.norm(T_target_cam[:3, 3]) * 1000
                color = (0, 255, 0) if is_stable else (0, 255, 255)
                cv2.putText(display, f"Distance: {dist_mm:.0f}mm", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                cv2.putText(
                    display,
                    "STABLE - SPACE" if is_stable else "Detecting...",
                    (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    color,
                    2,
                )
            else:
                cv2.putText(display, "Chessboard NOT FOUND", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                self.pose_buffer = []

            cv2.putText(
                display, f"Samples: {sample_count}", (display.shape[1] - 150, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2
            )
            cv2.imshow("Hand-Eye Calibration", display)

            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):
                print("\nğŸ‘‹ é€€å‡ºé‡‡é›†")
                break
            elif key == ord("h"):
                print("\nğŸ  æœºæ¢°è‡‚å›ä¸­...")
                self.controller.move_all_home()
                time.sleep(1)
            elif key == ord("s"):
                show_stability = not show_stability
            elif key == ord(" "):
                if not success:
                    print("âš ï¸  æœªæ£€æµ‹åˆ°æ£‹ç›˜æ ¼")
                    continue
                if not is_stable:
                    print("âš ï¸  ä½å§¿ä¸ç¨³å®šï¼Œå»ºè®®ç­‰å¾…ç¨³å®šåå†é‡‡é›†")

                T_to_save = self.get_averaged_pose() if self.get_averaged_pose() is not None else T_target_cam
                sample_count += 1
                print(f"\nğŸ“¸ é‡‡é›† #{sample_count}")

                T_gripper_base, q = self.read_robot_pose(verbose=True)
                self.T_target_cam_list.append(T_to_save.copy())
                self.T_gripper_base_list.append(T_gripper_base.copy())
                self.images.append(frame.copy())

                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                np.savez(
                    os.path.join(self.output_dir, f"pose_{sample_count:02d}_{ts}.npz"),
                    T_target_cam=T_to_save,
                    T_gripper_base=T_gripper_base,
                    q=q,
                    reproj_error=reproj_error,
                )
                cv2.imwrite(os.path.join(self.output_dir, f"image_{sample_count:02d}_{ts}.jpg"), frame)
                print(f"   è·ç¦»: {np.linalg.norm(T_to_save[:3,3])*1000:.1f}mm | é‡æŠ•å½±: {reproj_error:.2f}px")
                self.pose_buffer = []

        cap.release()
        cv2.destroyAllWindows()
        print(f"\nğŸ“Š å…±é‡‡é›† {sample_count} ç»„æ•°æ®")
        return sample_count >= 3

    # ------------------------------------------------------------------
    # åŠ è½½æ•°æ®
    # ------------------------------------------------------------------
    def load_collected_data(self):
        pose_files = sorted(glob.glob(os.path.join(self.output_dir, "pose_*.npz")))
        if not pose_files:
            print(f"âŒ æœªæ‰¾åˆ°æ ‡å®šæ•°æ®: {self.output_dir}")
            return False
        self.T_target_cam_list = []
        self.T_gripper_base_list = []
        print(f"\nğŸ“‚ åŠ è½½æ ‡å®šæ•°æ®...")
        for f in pose_files:
            data = np.load(f)
            self.T_target_cam_list.append(data["T_target_cam"])
            self.T_gripper_base_list.append(data["T_gripper_base"])
            print(f"   âœ… {os.path.basename(f)}")
        print(f"\nå…±åŠ è½½ {len(self.T_target_cam_list)} ç»„æ•°æ®")
        return True

    # ------------------------------------------------------------------
    # æ ‡å®š
    # ------------------------------------------------------------------
    def calibrate(self, method=cv2.CALIB_HAND_EYE_TSAI):
        if len(self.T_target_cam_list) < 3:
            print("âŒ æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦ 3 ç»„")
            return None

        print(f"\nğŸ”„ å¼€å§‹æ‰‹çœ¼æ ‡å®š (æ•°æ®ç»„æ•°: {len(self.T_target_cam_list)})")

        R_g2b = [T[:3, :3] for T in self.T_gripper_base_list]
        t_g2b = [T[:3, 3].reshape(3, 1) for T in self.T_gripper_base_list]
        R_t2c = [T[:3, :3] for T in self.T_target_cam_list]
        t_t2c = [T[:3, 3].reshape(3, 1) for T in self.T_target_cam_list]

        R_c2g, t_c2g = cv2.calibrateHandEye(R_g2b, t_g2b, R_t2c, t_t2c, method=method)

        T_cam_gripper = np.eye(4)
        T_cam_gripper[:3, :3] = R_c2g
        T_cam_gripper[:3, 3] = t_c2g.squeeze()

        t_mm = t_c2g.squeeze() * 1000
        euler = R.from_matrix(R_c2g).as_euler("xyz", degrees=True)
        print("\nâœ… æ‰‹çœ¼æ ‡å®šå®Œæˆ (T_cam_gripper)")
        print("-" * 70)
        print(f"å¹³ç§» (mm): tx={t_mm[0]:.2f}, ty={t_mm[1]:.2f}, tz={t_mm[2]:.2f}")
        print(f"æ—‹è½¬ (Â°): roll={euler[0]:.2f}, pitch={euler[1]:.2f}, yaw={euler[2]:.2f}")
        print("-" * 70)
        return T_cam_gripper

    # ------------------------------------------------------------------
    # ä¸€è‡´æ€§è¯„ä¼° (è°ƒç”¨å…¬å…±æ¨¡å—)
    # ------------------------------------------------------------------
    def evaluate_calibration(self, T_cam_gripper):
        print("\nğŸ“Š æ ‡å®šç»“æœè¯„ä¼°")
        print("=" * 70)
        result = evaluate_eye_in_hand_consistency(
            T_cam_gripper, self.T_gripper_base_list, self.T_target_cam_list
        )
        print_consistency_report(result, "ä¸€è‡´æ€§è¯¯å·® (AX=XB)")
        print("=" * 70)

    # ------------------------------------------------------------------
    # ä¿å­˜ç»“æœ
    # ------------------------------------------------------------------
    def save_result(self, T_cam_gripper, filename="handeye_result.yaml"):
        if T_cam_gripper is None:
            return
        filepath = os.path.join(self.output_dir, filename)
        fs = cv2.FileStorage(filepath, cv2.FILE_STORAGE_WRITE)
        fs.write("T_cam_gripper", T_cam_gripper)
        R_mat = T_cam_gripper[:3, :3]
        t_vec = T_cam_gripper[:3, 3]
        euler = R.from_matrix(R_mat).as_euler("xyz", degrees=True)
        quat = R.from_matrix(R_mat).as_quat()
        fs.write("rotation_matrix", R_mat)
        fs.write("translation_vector", t_vec.reshape(3, 1))
        fs.write("euler_angles_deg", np.array(euler).reshape(3, 1))
        fs.write("quaternion_xyzw", np.array(quat).reshape(4, 1))
        fs.write("calibration_date", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        fs.write("num_samples", len(self.T_target_cam_list))
        fs.release()
        print(f"\nğŸ’¾ å·²ä¿å­˜: {filepath}")

        npy_path = os.path.join(self.output_dir, "handeye_result.npy")
        np.save(npy_path, T_cam_gripper)
        print(f"ğŸ’¾ å·²ä¿å­˜: {npy_path}")

        # å¤åˆ¶åˆ° vision æ ¹ç›®å½•
        root_yaml = os.path.join(os.path.dirname(__file__), "handeye_result.yaml")
        root_npy = os.path.join(os.path.dirname(__file__), "handeye_result.npy")
        shutil.copy(filepath, root_yaml)
        shutil.copy(npy_path, root_npy)
        print(f"ğŸ’¾ å·²å¤åˆ¶: {root_yaml}")

    def close(self):
        if self.controller:
            self.controller.close()
            print("ğŸ”Œ æ§åˆ¶å™¨å·²å…³é—­")


# ----------------------------------------------------------------------
# main
# ----------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(description="çœ¼åœ¨æ‰‹ä¸Šæ‰‹çœ¼æ ‡å®šå·¥å…·")
    parser.add_argument("--collect", action="store_true", help="é‡‡é›†æ ‡å®šæ•°æ®")
    parser.add_argument("--calibrate", action="store_true", help="æ‰§è¡Œæ ‡å®šè®¡ç®—")
    parser.add_argument("--all", action="store_true", help="é‡‡é›†+æ ‡å®š")
    parser.add_argument("--output-dir", default="./handeye_data_right", help="æ•°æ®ä¿å­˜ç›®å½•")
    parser.add_argument("--intrinsic", default="./config_data/camera_intrinsics_right.yaml", help="ç›¸æœºå†…å‚æ–‡ä»¶")
    parser.add_argument("--square-size", type=float, default=20.73, help="æ£‹ç›˜æ ¼æ–¹æ ¼å¤§å°(mm)")
    parser.add_argument("--port", default="/dev/ttyACM0", help="ä¸²å£")
    parser.add_argument("--video", type=int, default=0, help="è§†é¢‘è®¾å¤‡ID")
    args = parser.parse_args()

    calibrator = HandEyeCalibrator(
        board_size=(11, 8),
        square_size=args.square_size / 1000.0,
        intrinsic_file=args.intrinsic,
        output_dir=args.output_dir,
    )

    try:
        if args.collect or args.all:
            calibrator.init_robot(port=args.port)
            print("\nğŸ  æœºæ¢°è‡‚å›ä¸­...")
            calibrator.collect_data_interactive(cam_id=args.video)

        if args.calibrate or args.all or (not args.collect and not args.all):
            if not calibrator.T_target_cam_list:
                calibrator.load_collected_data()
            if calibrator.T_target_cam_list:
                T = calibrator.calibrate()
                if T is not None:
                    calibrator.evaluate_calibration(T)
                    calibrator.save_result(T)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
    finally:
        calibrator.close()


if __name__ == "__main__":
    main()
