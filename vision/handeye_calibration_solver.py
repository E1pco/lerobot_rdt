#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‹çœ¼æ ‡å®š (Eye-in-Hand) â€” Tsai-Lenz å®ç°
--------------------------------------
è¾“å…¥:
    dataset_eyeinhand/pose_*.npz
    æ¯ä¸ªæ–‡ä»¶åŒ…å«:
        T_target_cam: 4x4
        T_gripper_base: 4x4

è¾“å‡º:
    handeye_result.npy
"""

import os
import glob
import numpy as np
import cv2
from scipy.spatial.transform import Rotation as R
import matplotlib.pyplot as plt


# ============================================================
# æ•°æ®è½½å…¥ä¸éªŒè¯
# ============================================================

def load_poses(data_dir):
    pose_files = sorted(glob.glob(os.path.join(data_dir, "pose_*.npz")))
    T_target_cam, T_gripper_base = [], []
    for f in pose_files:
        data = np.load(f)
        T_target_cam.append(data["T_target_cam"])
        T_gripper_base.append(data["T_gripper_base"])
    print(f"âœ… åŠ è½½ {len(T_target_cam)} ç»„æ•°æ®ã€‚")
    return T_target_cam, T_gripper_base


def validate_data(T_target_cam, T_gripper_base):
    """éªŒè¯æ•°æ®çš„æœ‰æ•ˆæ€§å’Œå¤šæ ·æ€§"""
    print("\nğŸ” æ•°æ®éªŒè¯:")
    print(f"   é‡‡é›†çš„æ•°æ®å¯¹æ•°: {len(T_target_cam)}")

    if len(T_target_cam) < 3:
        print("   âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦ 3 ç»„æ•°æ®")
        return False

    # æ£€æŸ¥å¹³ç§»å¤šæ ·æ€§
    positions_cam = np.array([T[:3, 3] for T in T_target_cam])
    positions_gripper = np.array([T[:3, 3] for T in T_gripper_base])

    span_cam = np.max(positions_cam, axis=0) - np.min(positions_cam, axis=0)
    span_gripper = np.max(positions_gripper, axis=0) - np.min(positions_gripper, axis=0)

    print(f"\n   ç›¸æœºåæ ‡ç³»ä½ç½®èŒƒå›´: {np.round(span_cam*1000, 2)} mm")
    print(f"   æœ«ç«¯åæ ‡ç³»ä½ç½®èŒƒå›´: {np.round(span_gripper*1000, 2)} mm")

    if np.any(span_cam < 0.001) or np.any(span_gripper < 0.001):
        print("   âš ï¸  è­¦å‘Šï¼šæŸä¸ªæ–¹å‘çš„è¿åŠ¨èŒƒå›´è¿‡å°ï¼Œæ ‡å®šç²¾åº¦å¯èƒ½è¾ƒä½")

    # æ£€æŸ¥æ—‹è½¬å¤šæ ·æ€§
    rotations_cam = [R.from_matrix(T[:3, :3]) for T in T_target_cam]
    rotvecs_cam = np.array([r.as_rotvec() for r in rotations_cam])
    rot_span_cam = np.linalg.norm(np.max(rotvecs_cam, axis=0) - np.min(rotvecs_cam, axis=0))

    print(f"\n   ç›¸æœºæ—‹è½¬å¤šæ ·æ€§: {np.degrees(rot_span_cam):.2f} deg")

    if rot_span_cam < np.radians(5):
        print("   âš ï¸  è­¦å‘Šï¼šæ—‹è½¬å˜åŒ–ä¸è¶³ 5Â°ï¼Œæ ‡å®šå¯èƒ½é€€åŒ–")

    return True


# ============================================================
# ç›¸å¯¹è¿åŠ¨æ„é€  (A_i, B_i)
# ============================================================

def make_AB(T_target_cam, T_gripper_base):
    """æ„é€  Tsaiâ€“Lenz æ–¹ç¨‹æ‰€éœ€çš„ç›¸å¯¹è¿åŠ¨ A_i, B_i"""
    A_list, B_list = [], []
    for i in range(len(T_target_cam) - 1):
        # A_i = (T_tc[i+1])^-1 @ T_tc[i]
        A_list.append(np.linalg.inv(T_target_cam[i + 1]) @ T_target_cam[i])

        # B_i = T_gb[i+1] @ inv(T_gb[i])
        B_list.append(T_gripper_base[i + 1] @ np.linalg.inv(T_gripper_base[i]))
    return A_list, B_list


# ============================================================
# Tsai-Lenz æ–¹æ³•
# ============================================================

def rot_to_axis_angle(Rm):
    rot = R.from_matrix(Rm)
    angle = rot.magnitude()
    axis = rot.as_rotvec() / (angle + 1e-12)
    return axis, angle


def solve_rotation(A_list, B_list):
    """æ±‚è§£æ—‹è½¬çŸ©é˜µ R_X"""
    P, Q, weights = [], [], []
    for Ra, Rb in zip([A[:3, :3] for A in A_list], [B[:3, :3] for B in B_list]):
        axis_a, angle_a = rot_to_axis_angle(Ra)
        axis_b, angle_b = rot_to_axis_angle(Rb)

        # å°è§’åº¦å‡å°æƒé‡ (Huber é£æ ¼)
        weight = max(np.sin(angle_a / 2), 1e-3)

        P.append(axis_a * weight)
        Q.append(axis_b * weight)
        weights.append(weight)

    P, Q = np.array(P).T, np.array(Q).T
    H = P @ Q.T
    U, _, Vt = np.linalg.svd(H)
    det = np.linalg.det(U @ Vt)
    R_X = U @ np.diag([1, 1, det]) @ Vt

    print(f"\nğŸ“Š æ—‹è½¬æ±‚è§£ç»Ÿè®¡:")
    print(f"   æ•°æ®å¯¹æ•°: {len(A_list)}")
    print(f"   æƒé‡èŒƒå›´: [{np.min(weights):.4f}, {np.max(weights):.4f}]")
    print(f"   SVD æœ€å°å¥‡å¼‚å€¼: {np.linalg.svd(H)[1][-1]:.6f}")

    return R_X


def solve_translation(A_list, B_list, R_X):
    """æœ€å°äºŒä¹˜æ±‚è§£å¹³ç§» t_X"""
    M_list, b_list = [], []
    for A_i, B_i in zip(A_list, B_list):
        R_A, t_A = A_i[:3, :3], A_i[:3, 3].reshape(3, 1)
        R_B, t_B = B_i[:3, :3], B_i[:3, 3].reshape(3, 1)
        M_list.append(R_A - np.eye(3))
        b_list.append(R_X @ t_B - t_A)

    M = np.vstack(M_list)
    b = np.vstack(b_list)

    cond = np.linalg.cond(M)
    print(f"\nğŸ“Š å¹³ç§»æ±‚è§£ç»Ÿè®¡:")
    print(f"   M å½¢çŠ¶: {M.shape}")
    print(f"   æ¡ä»¶æ•°: {cond:.2e}")
    if cond > 1e10:
        print("   âš ï¸  è­¦å‘Šï¼šçŸ©é˜µç—…æ€ï¼Œç²¾åº¦å¯èƒ½æœ‰é™")

    t_X, residuals, rank, _ = np.linalg.lstsq(M, b, rcond=None)
    if residuals.size > 0:
        print(f"   æ®‹å·®èŒƒæ•°: {np.sqrt(residuals[0]):.6f}")
        print(f"   ç§©: {rank}/{M.shape[1]}")

    return t_X.squeeze()


# ============================================================
# ç²¾åº¦è¯„ä¼°
# ============================================================

def evaluate_handeye(T_target_cam, T_gripper_base, T_cam_gripper):
    """éªŒè¯ç»“æœ T_cam^gripper çš„ç²¾åº¦"""
    print("\nğŸ“ è¯„ä¼°æ ‡å®šç»“æœ...")
    print(f"   det(R_X): {np.linalg.det(T_cam_gripper[:3,:3]):.6f}")
    
    # è¯Šæ–­ä¿¡æ¯ï¼šæ‰“å°å‰å‡ ä¸ªæ•°æ®ç‚¹çš„å˜æ¢ä¿¡æ¯
    print("\nğŸ“Š å‰3ä¸ªæ•°æ®ç‚¹çš„è¯Šæ–­ä¿¡æ¯:")
    for i in range(min(3, len(T_target_cam))):
        print(f"\n   æ•°æ®ç‚¹ {i}:")
        print(f"     T_target^cam ä½ç½®: {T_target_cam[i][:3, 3]}")
        print(f"     T_gripper^base ä½ç½®: {T_gripper_base[i][:3, 3]}")

    T_target_base_all = []
    for i, (T_tc, T_gb) in enumerate(zip(T_target_cam, T_gripper_base)):
        # Eye-in-Hand éªŒè¯å…³ç³»:
        # solvePnP è¿”å›çš„å˜æ¢æ˜¯: p_cam = R @ p_obj + t
        # æ‰€ä»¥ T_tc æ˜¯ä»ç›®æ ‡åˆ°ç›¸æœºçš„å˜æ¢: T_target^cam
        # 
        # éªŒè¯é“¾å¼: T_target^base = T_gripper^base @ T_cam^gripper @ T_target^cam
        T_tb = T_gb @ T_cam_gripper @ T_tc
        T_target_base_all.append(T_tb)
        
        if i < 3:
            print(f"     è®¡ç®—çš„ T_target^base ä½ç½®: {T_tb[:3, 3]}")

    T_target_base_all = np.array(T_target_base_all)

    # å¹³ç§»è¯¯å·®
    positions = np.array([T[:3, 3] for T in T_target_base_all])
    pos_mean = np.mean(positions, axis=0)
    pos_err = np.linalg.norm(positions - pos_mean, axis=1)
    mean_pos_err = np.mean(pos_err)
    std_pos_err = np.std(pos_err)
    max_pos_err = np.max(pos_err)

    # æ—‹è½¬è¯¯å·®
    rotations = [R.from_matrix(T[:3, :3]) for T in T_target_base_all]
    rotvecs = np.array([r.as_rotvec() for r in rotations])
    rot_mean = np.mean(rotvecs, axis=0)
    rot_err = np.linalg.norm(rotvecs - rot_mean, axis=1)
    mean_rot_err = np.degrees(np.mean(rot_err))
    std_rot_err = np.degrees(np.std(rot_err))
    max_rot_err = np.degrees(np.max(rot_err))

    print("\n" + "="*50)
    print("ğŸ“Š æ ‡å®šç²¾åº¦è¯„ä¼°")
    print("="*50)
    print(f"å¹³ç§»åå·®: å‡å€¼={mean_pos_err*1000:.3f} mm, Ïƒ={std_pos_err*1000:.3f} mm, æœ€å¤§={max_pos_err*1000:.3f} mm")
    print(f"æ—‹è½¬åå·®: å‡å€¼={mean_rot_err:.3f}Â°, Ïƒ={std_rot_err:.3f}Â°, æœ€å¤§={max_rot_err:.3f}Â°")
    print("="*50)

    if mean_pos_err < 0.002 and mean_rot_err < 0.5:
        print("âœ… ç²¾åº¦è‰¯å¥½")
    elif mean_pos_err < 0.005 and mean_rot_err < 1.0:
        print("âš ï¸ ç²¾åº¦ä¸€èˆ¬ï¼Œå»ºè®®å¢åŠ é‡‡é›†å¤šæ ·æ€§")
    else:
        print("âŒ ç²¾åº¦ä¸è¶³ï¼Œè¯·æ£€æŸ¥æ•°æ®é‡‡é›†æˆ–æ ‡å®šè¾“å…¥")

    # å¯è§†åŒ–
    fig = plt.figure(figsize=(12, 4))
    ax1 = fig.add_subplot(131, projection='3d')
    ax1.scatter(positions[:, 0], positions[:, 1], positions[:, 2], c='b', label='Samples')
    ax1.scatter(pos_mean[0], pos_mean[1], pos_mean[2], c='r', marker='*', s=200, label='Mean')
    ax1.set_title("Target Positions in Base Frame")
    ax1.set_xlabel("X [m]"); ax1.set_ylabel("Y [m]"); ax1.set_zlabel("Z [m]")
    ax1.legend()

    ax2 = fig.add_subplot(132)
    ax2.plot(pos_err*1000, 'o-')
    ax2.axhline(mean_pos_err*1000, color='r', linestyle='--', label=f'Mean {mean_pos_err*1000:.2f}mm')
    ax2.set_xlabel("Index"); ax2.set_ylabel("Position Error [mm]"); ax2.grid(); ax2.legend()

    ax3 = fig.add_subplot(133)
    ax3.plot(rot_err, 'o-')
    ax3.axhline(mean_rot_err, color='r', linestyle='--', label=f'Mean {mean_rot_err:.2f}Â°')
    ax3.set_xlabel("Index"); ax3.set_ylabel("Rotation Error [Â°]"); ax3.grid(); ax3.legend()

    plt.tight_layout()
    # ä¿å­˜å›¾è¡¨è€Œä¸æ˜¾ç¤ºï¼ˆé¿å… GUI é˜»å¡ï¼‰
    plt.savefig('handeye_evaluation.png', dpi=100)
    print(f"âœ… è¯„ä¼°å›¾è¡¨å·²ä¿å­˜åˆ° handeye_evaluation.png")
    plt.close()


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main(data_dir="dataset_eyeinhand", save_file="handeye_result.npy"):
    T_target_cam, T_gripper_base = load_poses(data_dir)

    if not validate_data(T_target_cam, T_gripper_base):
        print("\nâŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œä¸­æ­¢ã€‚")
        return

    # ã€ä½¿ç”¨ OpenCV è‡ªå¸¦çš„æ‰‹çœ¼æ ‡å®š - å‚è€ƒ compute_in_hand.pyã€‘
    print("\nğŸ”§ ä½¿ç”¨ OpenCV cv2.calibrateHandEye è¿›è¡Œæ‰‹çœ¼æ ‡å®š...")
    
    # å‡†å¤‡æ•°æ®ï¼šä»å˜æ¢çŸ©é˜µä¸­æå–æ—‹è½¬å’Œå¹³ç§»
    R_gripper2base = []
    t_gripper2base = []
    R_target2cam = []
    t_target2cam = []
    
    for T_gb, T_tc in zip(T_gripper_base, T_target_cam):
        # æœ«ç«¯ç›¸å¯¹äºåŸºåº§çš„æ—‹è½¬å’Œå¹³ç§»
        R_gripper2base.append(T_gb[:3, :3])
        t_gripper2base.append(T_gb[:3, 3].reshape(3, 1))
        
        # ç›®æ ‡ç›¸å¯¹äºç›¸æœºçš„æ—‹è½¬å’Œå¹³ç§»ï¼ˆä» solvePnP å¾—åˆ°ï¼‰
        R_target2cam.append(T_tc[:3, :3])
        t_target2cam.append(T_tc[:3, 3].reshape(3, 1))
    
    print(f"   è¾“å…¥æ•°æ®: {len(R_gripper2base)} ç»„ä½å§¿å¯¹")
    
    # è°ƒç”¨ OpenCV æ‰‹çœ¼æ ‡å®šï¼ˆTsai æ–¹æ³•ï¼‰
    R_cam2gripper, t_cam2gripper = cv2.calibrateHandEye(
        R_gripper2base, t_gripper2base,
        R_target2cam, t_target2cam,
        method=cv2.CALIB_HAND_EYE_TSAI
    )
    
    T_cam_gripper = np.eye(4)
    T_cam_gripper[:3, :3] = R_cam2gripper
    T_cam_gripper[:3, 3] = t_cam2gripper.squeeze()
    
    print("\n" + "="*50)
    print("âœ… OpenCV æ‰‹çœ¼æ ‡å®šç»“æœ (T_cam^gripper)")
    print("="*50)
    print(T_cam_gripper)
    print("\næ—‹è½¬çŸ©é˜µ det:", np.linalg.det(R_cam2gripper))
    
    # è½¬æ¢ä¸ºå››å…ƒæ•°ï¼ˆä¾¿äºç†è§£å§¿æ€ï¼‰
    from scipy.spatial.transform import Rotation as Rot
    quat = Rot.from_matrix(R_cam2gripper).as_quat()
    print(f"å››å…ƒæ•° [x, y, z, w]: {quat}")
    print(f"å¹³ç§»å‘é‡ [x, y, z]: {t_cam2gripper.squeeze()}")
    print("="*50)

    # æ„é€  A, B
    A_list, B_list = make_AB(T_target_cam, T_gripper_base)

    # Tsaiâ€“Lenz æ±‚è§£ï¼ˆè‡ªå·±å®ç°ï¼‰
    R_X = solve_rotation(A_list, B_list)
    t_X = solve_translation(A_list, B_list, R_X)

    T_cam_gripper = np.eye(4)
    T_cam_gripper[:3, :3] = R_X
    T_cam_gripper[:3, 3] = t_X

    print("\n" + "="*50)
    print("âœ… Tsai-Lenz æ‰‹çœ¼æ ‡å®šç»“æœ")
    print("="*50)
    np.set_printoptions(precision=6, suppress=True)
    print("T_cam^gripper =\n", T_cam_gripper)
    print("="*50)

    np.save(save_file, T_cam_gripper)
    print(f"âœ… å·²ä¿å­˜ç»“æœåˆ° {save_file}")

    # ============================================================
    # å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„ç²¾åº¦
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ“Š ä¸¤ç§æ–¹æ³•ç²¾åº¦å¯¹æ¯”")
    print("="*70)
    
    # é‡æ–°æ„é€  OpenCV ç»“æœçš„ T_cam_gripper
    T_cam_gripper_opencv = np.eye(4)
    T_cam_gripper_opencv[:3, :3] = R_cam2gripper
    T_cam_gripper_opencv[:3, 3] = t_cam2gripper.squeeze()
    
    print("\nã€æ–¹æ³• 1ã€‘OpenCV cv2.calibrateHandEye (Tsai æ–¹æ³•)")
    print("-" * 70)
    evaluate_handeye(T_target_cam, T_gripper_base, T_cam_gripper_opencv)
    
    print("\nã€æ–¹æ³• 2ã€‘è‡ªå®ç° Tsai-Lenz æ–¹æ³•")
    print("-" * 70)
    evaluate_handeye(T_target_cam, T_gripper_base, T_cam_gripper)
    
    # ============================================================
    # ä¸¤ä¸ªç»“æœçš„å·®å¼‚åˆ†æ
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ“Š ä¸¤ä¸ªç»“æœçš„å·®å¼‚åˆ†æ")
    print("="*70)
    
    T_diff = np.linalg.inv(T_cam_gripper_opencv) @ T_cam_gripper
    R_diff = T_diff[:3, :3]
    t_diff = T_diff[:3, 3]
    
    # æ—‹è½¬å·®å¼‚
    rot_diff = R.from_matrix(R_diff)
    angle_diff = np.degrees(rot_diff.magnitude())
    
    print(f"\næ—‹è½¬çŸ©é˜µå·®å¼‚:")
    print(f"   æ—‹è½¬è§’åº¦å·®: {angle_diff:.2f}Â°")
    print(f"   æ—‹è½¬å‘é‡: {rot_diff.as_rotvec()}")
    
    print(f"\nå¹³ç§»å‘é‡å·®å¼‚:")
    print(f"   å¹³ç§»å·® (mm): {t_diff * 1000}")
    print(f"   å¹³ç§»å·®èŒƒæ•° (mm): {np.linalg.norm(t_diff) * 1000:.2f}")
    
    # è¯Šæ–­ï¼šæ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰é—®é¢˜
    print("\n" + "="*70)
    print("ğŸ” æ•°æ®è´¨é‡è¯Šæ–­")
    print("="*70)
    
    # æ£€æŸ¥æ¯å¯¹æ•°æ®çš„ä¸€è‡´æ€§
    print("\næ£€æŸ¥æ¯å¯¹æ•°æ®çš„å˜æ¢ä¸€è‡´æ€§:")
    print("(éªŒè¯ Eye-in-Hand å…³ç³»æ˜¯å¦æ»¡è¶³)")
    
    consistency_errors = []
    for i in range(len(T_target_cam)):
        # ä½¿ç”¨ OpenCV ç»“æœè¿›è¡ŒéªŒè¯
        T_target_base_i = T_gripper_base[i] @ T_cam_gripper_opencv @ T_target_cam[i]
        consistency_errors.append(T_target_base_i[:3, 3])
    
    consistency_errors = np.array(consistency_errors)
    pos_consistency = np.linalg.norm(consistency_errors - np.mean(consistency_errors, axis=0), axis=1)
    
    print(f"   è®¡ç®—çš„ T_target^base ä½ç½®ä¸€è‡´æ€§ (mm):")
    print(f"     å‡å€¼åå·®: {np.mean(pos_consistency)*1000:.2f} mm")
    print(f"     æ ‡å‡†å·®: {np.std(pos_consistency)*1000:.2f} mm")
    print(f"     æœ€å¤§åå·®: {np.max(pos_consistency)*1000:.2f} mm")
    
    if np.mean(pos_consistency) > 0.1:
        print("   âš ï¸  è­¦å‘Š: T_target åœ¨åŸºåº§åæ ‡ç³»ä¸­å˜åŒ–è¿‡å¤§ï¼Œè¯´æ˜:")
        print("      - æ ‡å®šæ¿ä½ç½®åœ¨é‡‡é›†ä¸­å˜åŒ–ï¼ˆåº”è¯¥å›ºå®šï¼‰")
        print("      - æˆ–è€…æ‰‹çœ¼æ ‡å®šæ•°æ®æœ‰è¾ƒå¤§å™ªå£°")
        print("      - æˆ–è€… solvePnP ç²¾åº¦ä¸è¶³")


# ============================================================
# é«˜çº§è¯Šæ–­å·¥å…·
# ============================================================

def diagnose_data_quality(T_target_cam, T_gripper_base, T_cam_gripper):
    """æ·±åº¦è¯Šæ–­æ‰‹çœ¼æ ‡å®šæ•°æ®è´¨é‡"""
    print("\n" + "="*70)
    print("ğŸ”¬ æ·±åº¦æ•°æ®è´¨é‡è¯Šæ–­")
    print("="*70)
    
    # 1. æ£€æŸ¥æ ‡å®šæ¿æ˜¯å¦çœŸçš„æ˜¯å›ºå®šçš„
    print("\nã€è¯Šæ–­ 1ã€‘æ ‡å®šæ¿å›ºå®šæ€§æ£€æŸ¥")
    print("-" * 70)
    
    positions_base = []
    for i, (T_tc, T_gb) in enumerate(zip(T_target_cam, T_gripper_base)):
        T_target_base = T_gb @ T_cam_gripper @ T_tc
        positions_base.append(T_target_base[:3, 3])
    
    positions_base = np.array(positions_base)
    pos_std = np.std(positions_base, axis=0)
    pos_range = np.max(positions_base, axis=0) - np.min(positions_base, axis=0)
    
    print(f"T_target åœ¨åŸºåº§åæ ‡ç³»ä¸­çš„æ ‡å‡†å·® (mm): {pos_std * 1000}")
    print(f"T_target åœ¨åŸºåº§åæ ‡ç³»ä¸­çš„èŒƒå›´ (mm): {pos_range * 1000}")
    
    if np.any(pos_std > 0.1):
        print("âŒ ä¸¥é‡é—®é¢˜: æ ‡å®šæ¿ä½ç½®åœ¨é‡‡é›†ä¸­å‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–")
        print("   å¯èƒ½åŸå› :")
        print("   â€¢ æ ‡å®šæ¿åœ¨æœºæ¢°è‡‚è¿åŠ¨è¿‡ç¨‹ä¸­ç§»åŠ¨")
        print("   â€¢ æ ‡å®šæ¿å®‰è£…ä¸å¤Ÿç‰¢å›º")
        print("   â€¢ solvePnP ç»™å‡ºçš„ä½å§¿æœ‰è¾ƒå¤§è¯¯å·®")
    else:
        print("âœ… æ ‡å®šæ¿ä½ç½®ç¨³å®š")
    
    # 2. æ£€æŸ¥æœ«ç«¯æ‰§è¡Œå™¨çš„è¿åŠ¨æ˜¯å¦å……åˆ†
    print("\nã€è¯Šæ–­ 2ã€‘æœ«ç«¯æ‰§è¡Œå™¨è¿åŠ¨å……åˆ†æ€§æ£€æŸ¥")
    print("-" * 70)
    
    positions_gripper = np.array([T[:3, 3] for T in T_gripper_base])
    pos_gripper_std = np.std(positions_gripper, axis=0)
    pos_gripper_range = np.max(positions_gripper, axis=0) - np.min(positions_gripper, axis=0)
    
    print(f"æœ«ç«¯ä½ç½®æ ‡å‡†å·® (mm): {pos_gripper_std * 1000}")
    print(f"æœ«ç«¯ä½ç½®èŒƒå›´ (mm): {pos_gripper_range * 1000}")
    
    if np.any(pos_gripper_range < 0.05):
        print("âš ï¸  è­¦å‘Š: æŸä¸ªæ–¹å‘çš„è¿åŠ¨èŒƒå›´å¤ªå° (< 50mm)")
        print("   å¯èƒ½å¯¼è‡´æ‰‹çœ¼æ ‡å®šçŸ©é˜µå¥‡å¼‚")
    else:
        print("âœ… æœ«ç«¯è¿åŠ¨å……åˆ†")
    
    # 3. æ¯”è¾ƒ solvePnP ç»“æœå’Œè¿åŠ¨å­¦çš„ä¸€è‡´æ€§
    print("\nã€è¯Šæ–­ 3ã€‘solvePnP ä¸è¿åŠ¨å­¦ä¸€è‡´æ€§æ£€æŸ¥")
    print("-" * 70)
    
    print("åˆ†ææ¯å¯¹è¿ç»­é‡‡é›†ä¹‹é—´çš„ç›¸å¯¹è¿åŠ¨...")
    
    for i in range(min(3, len(T_target_cam) - 1)):
        # ä» solvePnP å¾—åˆ°çš„ç›¸å¯¹è¿åŠ¨
        T_rel_cam = np.linalg.inv(T_target_cam[i+1]) @ T_target_cam[i]
        
        # ä»æœ«ç«¯ä½å§¿å¾—åˆ°çš„ç›¸å¯¹è¿åŠ¨
        T_rel_gripper = np.linalg.inv(T_gripper_base[i+1]) @ T_gripper_base[i]
        
        # å¦‚æœæ‰‹çœ¼æ ‡å®šæ­£ç¡®ï¼Œè¿™ä¸¤ä¸ªç›¸å¯¹è¿åŠ¨åº”è¯¥åœ¨æ‰‹çœ¼å˜æ¢ä¸‹ç›¸åŒ
        # T_rel_gripper = inv(T_cg) @ T_rel_cam @ T_cg
        
        rel_cam_pos = T_rel_cam[:3, 3]
        rel_gripper_pos = T_rel_gripper[:3, 3]
        
        print(f"\n   æ•°æ®å¯¹ [{i}, {i+1}]:")
        print(f"     ç›¸æœºè§‚æµ‹çš„ç›¸å¯¹è¿åŠ¨ (mm): {rel_cam_pos * 1000}")
        print(f"     æœ«ç«¯ä½å§¿çš„ç›¸å¯¹è¿åŠ¨ (mm): {rel_gripper_pos * 1000}")
        
        # æ—‹è½¬éƒ¨åˆ†
        R_rel_cam = R.from_matrix(T_rel_cam[:3, :3])
        R_rel_gripper = R.from_matrix(T_rel_gripper[:3, :3])
        
        angle_cam = np.degrees(R_rel_cam.magnitude())
        angle_gripper = np.degrees(R_rel_gripper.magnitude())
        
        print(f"     ç›¸æœºè§‚æµ‹çš„æ—‹è½¬ (deg): {angle_cam:.2f}Â°")
        print(f"     æœ«ç«¯ä½å§¿çš„æ—‹è½¬ (deg): {angle_gripper:.2f}Â°")
    
    # 4. è¯„ä¼°æ‰‹çœ¼æ ‡å®šçŸ©é˜µçš„æ¡ä»¶æ•°
    print("\nã€è¯Šæ–­ 4ã€‘æ‰‹çœ¼æ ‡å®šç³»ç»Ÿçš„æ¡ä»¶æ•°")
    print("-" * 70)
    
    A_list, B_list = make_AB(T_target_cam, T_gripper_base)
    
    # æ—‹è½¬éƒ¨åˆ†æ¡ä»¶æ•°
    P, Q = [], []
    for Ra, Rb in zip([A[:3, :3] for A in A_list], [B[:3, :3] for B in B_list]):
        axis_a, angle_a = rot_to_axis_angle(Ra)
        axis_b, angle_b = rot_to_axis_angle(Rb)
        weight = max(np.sin(angle_a / 2), 1e-3)
        P.append(axis_a * weight)
        Q.append(axis_b * weight)
    
    P, Q = np.array(P).T, np.array(Q).T
    H = P @ Q.T
    
    _, singular_vals, _ = np.linalg.svd(H)
    cond_rot = singular_vals[0] / singular_vals[-1]
    
    print(f"æ—‹è½¬æ±‚è§£çš„å¥‡å¼‚å€¼: {singular_vals}")
    print(f"æ—‹è½¬æ±‚è§£çš„æ¡ä»¶æ•°: {cond_rot:.2e}")
    
    if cond_rot > 100:
        print("âš ï¸  è­¦å‘Š: æ—‹è½¬æ±‚è§£æ¡ä»¶æ•°è¿‡å¤§ï¼Œè¯´æ˜æ—‹è½¬å˜åŒ–ä¸å¤Ÿå¤šæ ·åŒ–")
    
    # å¹³ç§»éƒ¨åˆ†æ¡ä»¶æ•°
    M_list = []
    for A_i in A_list:
        R_A = A_i[:3, :3]
        M_list.append(R_A - np.eye(3))
    
    M = np.vstack(M_list)
    cond_trans = np.linalg.cond(M)
    
    print(f"å¹³ç§»æ±‚è§£çš„æ¡ä»¶æ•°: {cond_trans:.2e}")
    
    if cond_trans > 1e4:
        print("âš ï¸  è­¦å‘Š: å¹³ç§»æ±‚è§£æ¡ä»¶æ•°è¿‡å¤§ï¼ŒçŸ©é˜µç—…æ€")


if __name__ == "__main__":
    T_target_cam, T_gripper_base = load_poses("dataset_eyeinhand")
    if validate_data(T_target_cam, T_gripper_base):
        main()
        
        # åŠ è½½ç»“æœè¿›è¡Œæ·±åº¦è¯Šæ–­
        T_cam_gripper = np.load("handeye_result.npy")
        diagnose_data_quality(T_target_cam, T_gripper_base, T_cam_gripper)
