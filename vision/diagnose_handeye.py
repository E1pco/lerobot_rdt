import os
import sys
import cv2
import numpy as np
import glob
from scipy.spatial.transform import Rotation as R
import itertools

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from ik.robot import create_so101_5dof_gripper

def load_data(data_dir='./handeye_data'):
    pose_files = sorted(glob.glob(os.path.join(data_dir, "pose_*.npz")))
    if not pose_files:
        print(f"âŒ æœªæ‰¾åˆ°æ ‡å®šæ•°æ®: {data_dir}")
        return None, None
    
    T_target_cam_list = []
    T_gripper_base_list = []
    q_list = []
    
    print(f"ğŸ“‚ åŠ è½½æ ‡å®šæ•°æ®: {len(pose_files)} ç»„")
    for f in pose_files:
        data = np.load(f)
        T_target_cam_list.append(data['T_target_cam'])
        T_gripper_base_list.append(data['T_gripper_base'])
        if 'q' in data:
            q_list.append(data['q'])
        
    return T_gripper_base_list, T_target_cam_list, q_list

def check_data_quality(T_gripper_base_list, T_target_cam_list):
    print("\nğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥ (æ—‹è½¬åˆ†å¸ƒ)")
    print("-" * 50)
    
    rotations = []
    for T in T_gripper_base_list:
        rotations.append(R.from_matrix(T[:3, :3]))
    
    # è®¡ç®—ç›¸å¯¹äºç¬¬ä¸€ä¸ªä½å§¿çš„æ—‹è½¬è½´å’Œè§’åº¦
    base_rot = rotations[0]
    angles = []
    axes = []
    
    for i in range(1, len(rotations)):
        rel_rot = rotations[i] * base_rot.inv()
        angle = rel_rot.magnitude() * 180 / np.pi
        axis = rel_rot.as_rotvec() / (rel_rot.magnitude() + 1e-8)
        angles.append(angle)
        axes.append(axis)
        print(f"  Pose {i} vs Pose 0: è§’åº¦ = {angle:6.2f}Â°")
        
    print(f"\n  æœ€å¤§æ—‹è½¬è§’åº¦: {max(angles):.2f}Â°")
    print(f"  å¹³å‡æ—‹è½¬è§’åº¦: {np.mean(angles):.2f}Â°")
    
    if max(angles) < 10:
        print("  âš ï¸  è­¦å‘Š: æ—‹è½¬è§’åº¦è¿‡å°ï¼Œå¯èƒ½å¯¼è‡´æ ‡å®šä¸å‡†ç¡®ï¼å»ºè®®è‡³å°‘åŒ…å« >15Â° çš„æ—‹è½¬ã€‚")
    
    # æ£€æŸ¥æ ‡å®šæ¿ä½å§¿çš„è¿ç»­æ€§ (æ’æŸ¥ PnP Flip)
    print("\nğŸ“Š æ ‡å®šæ¿ä½å§¿è¿ç»­æ€§æ£€æŸ¥ (T_target_cam)")
    print("-" * 50)
    rotations_tc = [R.from_matrix(T[:3, :3]) for T in T_target_cam_list]
    base_rot_tc = rotations_tc[0]
    
    for i in range(1, len(rotations_tc)):
        rel_rot = rotations_tc[i] * rotations_tc[i-1].inv()
        angle = rel_rot.magnitude() * 180 / np.pi
        print(f"  Frame {i} vs {i-1}: ç›¸å¯¹æ—‹è½¬ = {angle:6.2f}Â°")
        if angle > 90:
             print(f"  âš ï¸  è­¦å‘Š: Frame {i} ç›¸å¯¹ä¸Šä¸€å¸§æ—‹è½¬è¿‡å¤§ ({angle:.1f}Â°)ï¼Œå¯èƒ½æ˜¯æ£‹ç›˜æ ¼æ£€æµ‹ç¿»è½¬ (Flip)ï¼")

def evaluate_calibration_correct(T_gripper_base_list, T_target_cam_list, T_cam_gripper):
    print("\nğŸ“‰ æ ‡å®šä¸€è‡´æ€§è¯„ä¼° (AX = XB)")
    print("-" * 50)
    
    errors_trans = []
    errors_rot = []
    
    for i in range(len(T_gripper_base_list)):
        for j in range(i + 1, len(T_gripper_base_list)):
            T_gb1 = T_gripper_base_list[i]
            T_gb2 = T_gripper_base_list[j]
            T_tc1 = T_target_cam_list[i]
            T_tc2 = T_target_cam_list[j]
            
            # A = T_g2_g1 = inv(T_b_g2) * T_b_g1
            A = np.linalg.inv(T_gb2) @ T_gb1
            
            # B = T_c2_c1 = T_c2_t * T_t_c1 = T_c_t2 * inv(T_c_t1)
            # T_target_cam is T_c_t (Target in Camera)
            B = T_tc2 @ np.linalg.inv(T_tc1)
            
            # Check AX = XB
            # LHS = A * X
            LHS = A @ T_cam_gripper
            # RHS = X * B
            RHS = T_cam_gripper @ B
            
            # Error = LHS * inv(RHS)
            diff = LHS @ np.linalg.inv(RHS)
            
            trans_err = np.linalg.norm(diff[:3, 3]) * 1000
            rot_err = np.linalg.norm(R.from_matrix(diff[:3, :3]).as_rotvec()) * 180 / np.pi
            
            errors_trans.append(trans_err)
            errors_rot.append(rot_err)
            
    print(f"  å¹³å‡å¹³ç§»è¯¯å·®: {np.mean(errors_trans):.4f} mm")
    print(f"  æœ€å¤§å¹³ç§»è¯¯å·®: {np.max(errors_trans):.4f} mm")
    print(f"  å¹³å‡æ—‹è½¬è¯¯å·®: {np.mean(errors_rot):.4f} deg")
    print(f"  æœ€å¤§æ—‹è½¬è¯¯å·®: {np.max(errors_rot):.4f} deg")
    
    return np.mean(errors_trans), np.mean(errors_rot)

def run_calibration(T_gripper_base_list, T_target_cam_list):
    methods = [
        (cv2.CALIB_HAND_EYE_TSAI, "Tsai-Lenz"),
        (cv2.CALIB_HAND_EYE_PARK, "Park"),
        (cv2.CALIB_HAND_EYE_HORAUD, "Horaud"),
        (cv2.CALIB_HAND_EYE_ANDREFF, "Andreff"),
        (cv2.CALIB_HAND_EYE_DANIILIDIS, "Daniilidis")
    ]
    
    R_gripper2base = []
    t_gripper2base = []
    R_target2cam = []
    t_target2cam = []
    
    for T_gb, T_tc in zip(T_gripper_base_list, T_target_cam_list):
        R_gripper2base.append(T_gb[:3, :3])
        t_gripper2base.append(T_gb[:3, 3].reshape(3, 1))
        R_target2cam.append(T_tc[:3, :3])
        t_target2cam.append(T_tc[:3, 3].reshape(3, 1))
        
    best_error = float('inf')
    best_method = ""
    best_T = None
    
    print("\nğŸ”„ å°è¯•ä¸åŒæ ‡å®šç®—æ³•:")
    print("-" * 50)
    
    for method_enum, method_name in methods:
        try:
            R_cg, t_cg = cv2.calibrateHandEye(
                R_gripper2base, t_gripper2base,
                R_target2cam, t_target2cam,
                method=method_enum
            )
            
            T_cg = np.eye(4)
            T_cg[:3, :3] = R_cg
            T_cg[:3, 3] = t_cg.squeeze()
            
            print(f"\nğŸ”¹ æ–¹æ³•: {method_name}")
            t_err, r_err = evaluate_calibration_correct(T_gripper_base_list, T_target_cam_list, T_cg)
            
            score = t_err + r_err # ç®€å•åŠ æƒ
            if score < best_error:
                best_error = score
                best_method = method_name
                best_T = T_cg
                
            print(f"  ç»“æœ T_cg:\n{T_cg}")
            
        except Exception as e:
            print(f"  {method_name} å¤±è´¥: {e}")

    print("\nğŸ† æœ€ä½³æ–¹æ³•:", best_method)
    return best_T

def test_inversions(T_gripper_base_list, T_target_cam_list):
    print("\nğŸ” æµ‹è¯•ä¸åŒçš„è¾“å…¥æ•°æ®ç»„åˆ (æ’æŸ¥åæ ‡ç³»å®šä¹‰é—®é¢˜)")
    print("-" * 50)
    
    combinations = [
        ("åŸå§‹æ•°æ® (T_b_g, T_c_t)", False, False),
        ("æœºå™¨äººä½å§¿å–é€† (T_g_b, T_c_t)", True, False),
        ("æ ‡å®šæ¿ä½å§¿å–é€† (T_b_g, T_t_c)", False, True),
        ("ä¸¤è€…éƒ½å–é€† (T_g_b, T_t_c)", True, True)
    ]
    
    for name, inv_g, inv_t in combinations:
        print(f"\nğŸ‘‰ æµ‹è¯•: {name}")
        
        # å‡†å¤‡æ•°æ®
        T_gb_test = []
        T_tc_test = []
        
        for T_gb, T_tc in zip(T_gripper_base_list, T_target_cam_list):
            if inv_g:
                T_gb_test.append(np.linalg.inv(T_gb))
            else:
                T_gb_test.append(T_gb)
                
            if inv_t:
                T_tc_test.append(np.linalg.inv(T_tc))
            else:
                T_tc_test.append(T_tc)
        
        # è¿è¡Œæ ‡å®š (åªç”¨ Park æ–¹æ³•å¿«é€Ÿæµ‹è¯•)
        try:
            R_gripper2base = [T[:3, :3] for T in T_gb_test]
            t_gripper2base = [T[:3, 3].reshape(3, 1) for T in T_gb_test]
            R_target2cam = [T[:3, :3] for T in T_tc_test]
            t_target2cam = [T[:3, 3].reshape(3, 1) for T in T_tc_test]
            
            R_cg, t_cg = cv2.calibrateHandEye(
                R_gripper2base, t_gripper2base,
                R_target2cam, t_target2cam,
                method=cv2.CALIB_HAND_EYE_PARK
            )
            
            T_cg = np.eye(4)
            T_cg[:3, :3] = R_cg
            T_cg[:3, 3] = t_cg.squeeze()
            
            evaluate_calibration_correct(T_gb_test, T_tc_test, T_cg)
            
        except Exception as e:
            print(f"  å¤±è´¥: {e}")

def optimize_kinematics(q_list, T_target_cam_list):
    print("\nğŸ”§ å°è¯•ä¼˜åŒ–è¿åŠ¨å­¦å‚æ•° (Gear Signs)")
    print("-" * 50)
    
    if not q_list:
        print("âŒ æ²¡æœ‰å…³èŠ‚è§’åº¦æ•°æ®ï¼Œæ— æ³•ä¼˜åŒ–")
        return

    # è·å–æœºå™¨äººæ¨¡å‹
    robot = create_so101_5dof_gripper()
    joint_names = robot.joint_names
    
    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç¬¦å·ç»„åˆ (+1, -1)
    signs = [1, -1]
    combinations = list(itertools.product(signs, repeat=len(joint_names)))
    
    best_error = float('inf')
    best_signs = None
    
    print(f"  æµ‹è¯• {len(combinations)} ç§ç¬¦å·ç»„åˆ...")
    
    for i, sign_combo in enumerate(combinations):
        # æ›´æ–° gear_sign
        current_gear_sign = {name: s for name, s in zip(joint_names, sign_combo)}
        robot.gear_sign = current_gear_sign
        
        # é‡æ–°è®¡ç®— FK
        T_gb_new = []
        for q in q_list:
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ q å·²ç»æ˜¯å¼§åº¦ï¼Œä¸”å·²ç»åº”ç”¨äº†åŸå§‹çš„ gear_sign
            # æˆ‘ä»¬éœ€è¦åæ¨åŸå§‹ steps æˆ–è€…å‡è®¾ q æ˜¯ raw values?
            # read_joint_angles è¿”å›çš„æ˜¯ q = sign * (step - home) / scale
            # å¦‚æœæˆ‘ä»¬æƒ³æ”¹å˜ signï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“åŸå§‹çš„ (step - home) / scale
            # å‡è®¾åŸå§‹ sign æ˜¯æ­£ç¡®çš„? ä¸ï¼Œæˆ‘ä»¬æ€€ç–‘åŸå§‹ sign æ˜¯é”™çš„ã€‚
            # ä½†æ˜¯ q_list ä¿å­˜çš„æ˜¯å·²ç»è®¡ç®—å¥½çš„ qã€‚
            # å¦‚æœåŸå§‹ sign æ˜¯ s_oldï¼Œæ–° sign æ˜¯ s_newã€‚
            # q_new = q_old * (s_new / s_old)
            
            # è·å–åŸå§‹ sign
            # create_so101_5dof_gripper é»˜è®¤çš„ sign
            orig_signs = [-1, 1, 1, -1, 1] # shoulder_pan, shoulder_lift, elbow_flex, wrist_flex, wrist_roll
            
            q_new = q.copy()
            for j, name in enumerate(joint_names):
                s_old = orig_signs[j]
                s_new = sign_combo[j]
                q_new[j] = q[j] * (s_new / s_old)
            
            T_gb_new.append(robot.fkine(q_new))
            
        # è¿è¡Œæ ‡å®šè¯„ä¼°
        try:
            R_gripper2base = [T[:3, :3] for T in T_gb_new]
            t_gripper2base = [T[:3, 3].reshape(3, 1) for T in T_gb_new]
            R_target2cam = [T[:3, :3] for T in T_target_cam_list]
            t_target2cam = [T[:3, 3].reshape(3, 1) for T in T_target_cam_list]
            
            R_cg, t_cg = cv2.calibrateHandEye(
                R_gripper2base, t_gripper2base,
                R_target2cam, t_target2cam,
                method=cv2.CALIB_HAND_EYE_PARK
            )
            
            T_cg = np.eye(4)
            T_cg[:3, :3] = R_cg
            T_cg[:3, 3] = t_cg.squeeze()
            
            # è®¡ç®—è¯¯å·®
            t_err, r_err = evaluate_calibration_correct(T_gb_new, T_target_cam_list, T_cg)
            score = t_err + r_err
            
            if score < best_error:
                best_error = score
                best_signs = sign_combo
                print(f"  [{i}] æ–°æœ€ä½³: Err={score:.2f} (T={t_err:.1f}mm, R={r_err:.1f}Â°) Signs={sign_combo}")
                
        except Exception:
            pass
            
    print("\nğŸ† æœ€ä½³ç¬¦å·ç»„åˆ:", best_signs)
    print("  åŸå§‹ç»„åˆ: (-1, 1, 1, -1, 1)")

if __name__ == "__main__":
    T_gb, T_tc, qs = load_data()
    if T_gb:
        check_data_quality(T_gb, T_tc)
        test_inversions(T_gb, T_tc)
        if qs:
            optimize_kinematics(qs, T_tc)
        # run_calibration(T_gb, T_tc)
