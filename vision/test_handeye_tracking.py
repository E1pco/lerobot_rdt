#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‹çœ¼æ ‡å®šæ•ˆæœæµ‹è¯•è„šæœ¬ - è§†è§‰è·Ÿéš
=====================================
åŠŸèƒ½:
  1. åŠ è½½æ‰‹çœ¼æ ‡å®šç»“æœ
  2. è¯†åˆ«æ£‹ç›˜æ ¼
  3. æ§åˆ¶æœºæ¢°è‡‚æœ«ç«¯è·Ÿéšæ£‹ç›˜æ ¼ (ä¿æŒå›ºå®šè·ç¦»å’Œå§¿æ€)

ä½¿ç”¨æ–¹æ³•:
  python vision/test_handeye_tracking.py
"""

import sys
import os
import cv2
import numpy as np
import time
from scipy.spatial.transform import Rotation as R

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from vision.handeye_calibration_eyeinhand import HandEyeCalibrator
from ik.robot import create_so101_5dof_gripper

def main():
    # 1. åŠ è½½æ ‡å®šç»“æœ
    calib_file = os.path.join(os.path.dirname(__file__), 'handeye_result.npy')
    if not os.path.exists(calib_file):
        print(f"âŒ æœªæ‰¾åˆ°æ ‡å®šæ–‡ä»¶: {calib_file}")
        return
    
    # æ³¨æ„ï¼šhandeye_calibration_eyeinhand.py ä¿å­˜çš„æ˜¯ cv2.calibrateHandEye è¾“å‡ºçš„ cam2gripper
    # å…¶ç‰©ç†å«ä¹‰ä¸º: ^G T_C (camera -> gripper)ï¼Œå³â€œç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹â€å˜æ¢åˆ°â€œæœ«ç«¯åæ ‡ç³»â€ã€‚
    # æœ¬è„šæœ¬é“¾å¼è®¡ç®—ä¼šç”¨åˆ° ^B T_C = ^B T_G @ ^G T_Cï¼Œå› æ­¤è¿™é‡Œä¸åº”å–é€†ã€‚
    T_cam_gripper = np.load(calib_file)
    print(f"âœ… å·²åŠ è½½æ‰‹çœ¼æ ‡å®šå‚æ•° (^G T_C, cam2gripper / camera->gripper):\n{T_cam_gripper}")
    
    # 2. åˆå§‹åŒ– (å¤ç”¨ HandEyeCalibrator çš„åˆå§‹åŒ–é€»è¾‘)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦ä¿å­˜æ•°æ®ï¼Œåªæ˜¯åˆ©ç”¨å®ƒçš„æ£€æµ‹å’Œæœºå™¨äººæ§åˆ¶åŠŸèƒ½
    # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ camera_intrinsics.yaml (ä¸ right.py ä¿æŒä¸€è‡´)
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    intrinsic_file = os.path.join(root_dir, './vision/camera_intrinsics.yaml')
    
    calibrator = HandEyeCalibrator(output_dir='/tmp', intrinsic_file=intrinsic_file)
    
    # å¼ºåˆ¶é‡ç½®æ–¹æ ¼å¤§å°ä¸º 0.02073 (å› ä¸º root yaml ä¸­å¯èƒ½æ˜¯ 0.025)
    target_square_size = 0.02073
    if abs(calibrator.square_size - target_square_size) > 0.0001:
        print(f"âš ï¸ å¼ºåˆ¶ä¿®æ­£æ–¹æ ¼å¤§å°: {calibrator.square_size*1000:.2f}mm -> {target_square_size*1000:.2f}mm")
        calibrator.square_size = target_square_size
        calibrator.objp = np.zeros((calibrator.board_size[0] * calibrator.board_size[1], 3), np.float32)
        calibrator.objp[:, :2] = np.mgrid[0:calibrator.board_size[0], 0:calibrator.board_size[1]].T.reshape(-1, 2)
        calibrator.objp *= calibrator.square_size
    
    # åº”ç”¨ç„¦è·ä¿®æ­£ç³»æ•°
    # 1. åŸå§‹ä¿®æ­£ (right.py): 600 / 647
    # 2. ç°åœºä¿®æ­£ (2025-12-24): æµ‹é‡å€¼ 250mm -> å®é™…å€¼ 230mm
    correction_factor = 1
    K_original_fx = calibrator.K[0, 0]
    K_original_fy = calibrator.K[1, 1]
    calibrator.K[0, 0] *= correction_factor  # fx
    calibrator.K[1, 1] *= correction_factor  # fy
    print(f"ğŸ“· ç„¦è·ä¿®æ­£ (factor={correction_factor:.4f}):")
    print(f"   åŸå§‹: fx={K_original_fx:.1f}, fy={K_original_fy:.1f}")
    print(f"   ä¿®æ­£å: fx={calibrator.K[0,0]:.1f}, fy={calibrator.K[1,1]:.1f}")

    if not calibrator.init_robot():
        return

    # 3. æ§åˆ¶å¾ªç¯
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    print("\nğŸ¤– æœºå™¨äººè§†è§‰è·Ÿéšæµ‹è¯•")
    print("========================================")
    print("æŒ‰é”®è¯´æ˜:")
    print("  'f' - å¼€å¯/å…³é—­ è·Ÿéšæ¨¡å¼ (Follow)")
    print("  'h' - æœºæ¢°è‡‚å›ä¸­ (Home)")
    print("  'q' - é€€å‡º")
    print("  --- è°ƒè¯•æ§åˆ¶ ---")
    print("  '1' - åˆ‡æ¢ ç›¸æœºXè½´ æ§åˆ¶ (å·¦å³)")
    print("  '2' - åˆ‡æ¢ ç›¸æœºYè½´ æ§åˆ¶ (ä¸Šä¸‹)")
    print("  '3' - åˆ‡æ¢ ç›¸æœºZè½´ æ§åˆ¶ (å‰å)")
    print("  'x' - åè½¬ ç›¸æœºXè½´ æ–¹å‘")
    print("  'y' - åè½¬ ç›¸æœºYè½´ æ–¹å‘")
    print("  'z' - åè½¬ ç›¸æœºZè½´ æ–¹å‘")
    print("  'm' - åˆ‡æ¢ æ˜ å°„æ¨¡å¼ (auto/manual)")
    print("  '7' - åˆ‡æ¢ Cam X æ˜ å°„ (Base X/Y/Z)")
    print("  '8' - åˆ‡æ¢ Cam Y æ˜ å°„ (Base X/Y/Z)")
    print("  '9' - åˆ‡æ¢ Cam Z æ˜ å°„ (Base X/Y/Z)")
    print("========================================")
    
    following = False
    target_distance = 0.30  # ç›®æ ‡è·ç¦» 30cm

    # ä½é¢‘è¯Šæ–­æ‰“å°ï¼šç”¨äºå¿«é€Ÿç¡®è®¤ FK/æ‰‹çœ¼çŸ©é˜µæ–¹å‘æ˜¯å¦è¢«ç”¨å
    diag_chain = True
    diag_every_n_frames = 30
    diag_frame_counter = 0

    # æ˜ å°„æ¨¡å¼:
    # - auto: é€šè¿‡æ‰‹çœ¼ + å½“å‰æœºæ¢°è‡‚ä½å§¿è®¡ç®— R_base_camï¼Œå®ç°åŠ¨æ€æ˜ å°„
    # - base_direct: ç›´æ¥åœ¨ Base åæ ‡ç³»ä¸‹æ§åˆ¶ï¼ˆæ¨èï¼Œé¿å… Z è½´æ¼‚ç§»ï¼‰
    # - manual: ä½¿ç”¨ axis_map/axis_sign çš„é™æ€æ˜ å°„ï¼ˆä»…è°ƒè¯•ç”¨ï¼‰
    mapping_mode = "base_direct"
    
    # è½´æ§åˆ¶æ©ç  (1:å¯ç”¨, 0:ç¦ç”¨)
    axis_mask = np.array([1.0, 1.0, 1.0]) 
    # è½´æ–¹å‘ç¬¦å· (1:æ­£å‘, -1:åå‘)
    # åˆ†æ:
    # Gripper Z ~ Base -Y. Cam Z ~ Gripper Z. => Cam Z ~ Base -Y.
    # Cam Z err > 0 (too far) => Move Cam Z+ => Move Base Y- => Sign -1.
    # Gripper X ~ Base X. Cam X ~ Gripper X. => Cam X ~ Base X. => Sign 1.
    # Gripper Y ~ Base Z. Cam Y ~ Gripper Y. => Cam Y ~ Base Z. => Sign 1.
    axis_sign = np.array([1.0, 1.0, -1.0])
    
    # è½´æ˜ å°„: Cam Axis Index -> Base Axis Index
    # çœ¼åœ¨æ‰‹ä¸Šå…¸å‹é…ç½®:
    #   Cam Z (å‘å‰) -> Base X (å‘å‰)
    #   Cam X (å‘å³) -> Base Y (å‘å³) 
    #   Cam Y (å‘ä¸‹) -> Base Z (å‘ä¸‹)
    axis_map = np.array([1, 2, 0])  # Cam[0]->Base[1], Cam[1]->Base[2], Cam[2]->Base[0] 

    # è¯¯å·®æ­»åŒº(å•ä½: mm)ã€‚æŸä¸€è½´è¯¯å·®è¿›å…¥æ­»åŒºåï¼Œè¯¥è½´ä¸å†ç»§ç»­é©±åŠ¨(é¿å…â€œåˆ°ä½è¿˜åœ¨æŠ–/è¶Šèµ°è¶Šåâ€)
    tol_cam_mm = np.array([20.0, 20.0, 10.0])
    # å…¨éƒ¨è½´éƒ½è¿›å…¥æ­»åŒºåï¼Œè¿ç»­æ»¡è¶³ N å¸§æ‰çœŸæ­£åœæ­¢å‘æŒ‡ä»¤(é˜²æŠ–)
    stable_required = 5
    stable_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret: break
            
            display = frame.copy()
            
            # æ£€æµ‹æ£‹ç›˜æ ¼
            success, T_target_cam, corners, err = calibrator.detect_chessboard(frame, refine_pose=True)
            
            if success:
                diag_frame_counter += 1
                # ç»˜åˆ¶è§’ç‚¹
                cv2.drawChessboardCorners(display, calibrator.board_size, corners, True)
                # ç»˜åˆ¶åæ ‡è½´
                cv2.drawFrameAxes(display, calibrator.K, calibrator.dist, 
                                 T_target_cam[:3, :3], T_target_cam[:3, 3], 0.05)
                
                # --- æ ¸å¿ƒé€»è¾‘: è®¡ç®—ç›®æ ‡åœ¨åŸºåº§æ ‡ç³»ä¸‹çš„ä½å§¿ ---
                # 1. è·å–å½“å‰æœºæ¢°è‡‚ä½å§¿ T_gripper_base
                T_gripper_base, q_curr = calibrator.read_robot_pose(verbose=False)

                if diag_chain and (diag_frame_counter % diag_every_n_frames == 0):
                    # å‡è®¾ç»„åˆï¼šFKä¸º B_T_G æˆ– G_T_Bï¼›æ‰‹çœ¼ä¸º G_T_C æˆ– C_T_G
                    fk_candidates = {
                        "fk=B_T_G": T_gripper_base,
                        "fk=inv": np.linalg.inv(T_gripper_base),
                    }
                    he_candidates = {
                        "he=G_T_C": T_cam_gripper,
                        "he=inv": np.linalg.inv(T_cam_gripper),
                    }
                    parts = []
                    for fk_name, B_T_G in fk_candidates.items():
                        for he_name, G_T_C in he_candidates.items():
                            B_T_C = B_T_G @ G_T_C
                            B_T_T = B_T_C @ T_target_cam
                            p = (B_T_T[:3, 3] * 1000.0)
                            parts.append(f"{fk_name},{he_name}:[{p[0]:.0f},{p[1]:.0f},{p[2]:.0f}]")
                    print("[Diag Target(Base) mm] " + " | ".join(parts))
                
                # 2. è®¡ç®—ç›®æ ‡åœ¨åŸºåº§æ ‡ç³»ä¸‹çš„ä½å§¿ T_target_base
                # é“¾å¼æ³•åˆ™: ^B T_T = ^B T_G @ ^G T_C @ ^C T_T
                T_target_base = T_gripper_base @ T_cam_gripper @ T_target_cam
                
                # æ˜¾ç¤ºç›®æ ‡åæ ‡
                pos_target = T_target_base[:3, 3] * 1000
                cv2.putText(display, f"Target (Base): [{pos_target[0]:.0f}, {pos_target[1]:.0f}, {pos_target[2]:.0f}] mm", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºPnPç»“æœ (ç›¸æœºåæ ‡ç³»)
                pos_cam = T_target_cam[:3, 3] * 1000
                cv2.putText(display, f"PnP (Cam): [{pos_cam[0]:.1f}, {pos_cam[1]:.1f}, {pos_cam[2]:.1f}] mm", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                
                if following:
                    # --- è§†è§‰ä¼ºæœæ§åˆ¶ ---
                    
                    # 1. è®¡ç®—ç›¸æœºåæ ‡ç³»ä¸‹çš„è¯¯å·®
                    target_pos_in_cam = T_target_cam[:3, 3]
                    desired_pos_in_cam = np.array([0, 0, target_distance])
                    
                    # è¯¯å·®å‘é‡
                    error_in_cam = target_pos_in_cam - desired_pos_in_cam

                    # ---- è¯¯å·®æ­»åŒº + åœæœºåˆ¤å®š(ç›¸æœºåæ ‡ç³») ----
                    error_cam_mm = error_in_cam * 1000.0
                    in_tol_each = np.abs(error_cam_mm) < tol_cam_mm
                    if np.all(in_tol_each):
                        stable_count += 1
                    else:
                        stable_count = 0

                    # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºè¯¯å·®ä¸æ­»åŒºå‘½ä¸­æƒ…å†µ
                    cv2.putText(
                        display,
                        f"ErrCam(mm): [{error_cam_mm[0]:.0f}, {error_cam_mm[1]:.0f}, {error_cam_mm[2]:.0f}] tol:[{tol_cam_mm[0]:.0f},{tol_cam_mm[1]:.0f},{tol_cam_mm[2]:.0f}]",
                        (10, 150),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 255),
                        2,
                    )
                    cv2.putText(
                        display,
                        f"InTol(X,Y,Z): {int(in_tol_each[0])},{int(in_tol_each[1])},{int(in_tol_each[2])} stable:{stable_count}/{stable_required}",
                        (10, 175),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (255, 255, 255),
                        2,
                    )

                    # å¦‚æœæ•´ä½“å·²ç»ç¨³å®šåˆ°ä½ï¼Œå°±ä¸è¦ç»§ç»­å‘ä»»ä½•è¿åŠ¨æŒ‡ä»¤
                    if stable_count >= stable_required:
                        cv2.putText(display, "HOLD (in tolerance)", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                        continue

                    # å¯¹å•è½´â€œé”å®šâ€ï¼šè¿›å…¥æ­»åŒºçš„è½´ä¸å†é©±åŠ¨
                    error_in_cam_deadband = error_in_cam.copy()
                    error_in_cam_deadband[in_tol_each] = 0.0
                    
                    # 2. å°†ç›¸æœºè¯¯å·®æ˜ å°„åˆ°åŸºåº§(å¾—åˆ°æœ«ç«¯å¹³ç§»å¢é‡)
                    if mapping_mode == "base_direct":
                        # ç›´æ¥åœ¨ Base åæ ‡ç³»ä¸‹æ§åˆ¶ï¼šè®©å¤¹çˆªç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
                        # ç›®æ ‡ï¼šGripper ç§»åŠ¨åˆ° Target åœ¨ Base ä¸‹çš„ XY ä½ç½®ï¼ŒZ ä¿æŒä¸å˜
                        pos_target_base = T_target_base[:3, 3]
                        pos_gripper_base = T_gripper_base[:3, 3]
                        
                        # è¯¯å·®ç›´æ¥åœ¨ Base åæ ‡ç³»è®¡ç®—
                        error_base_direct = pos_target_base - pos_gripper_base
                        
                        # åªæ§åˆ¶ X å’Œ Yï¼ŒZ è½´ä¿æŒç¨³å®šï¼ˆè®¾ä¸º 0 æˆ–å¾ˆå°çš„å¢ç›Šï¼‰
                        delta_base = np.array([
                            error_base_direct[0] * axis_mask[0],  # X
                            error_base_direct[1] * axis_mask[1],  # Y  
                            error_base_direct[2] * axis_mask[2] * 0.1  # Z ç”¨å°å¢ç›Šé¿å…æ¼‚ç§»
                        ])
                    elif mapping_mode == "auto":
                        # åŠ¨æ€æ˜ å°„ï¼šv_base = R_base_cam @ v_cam
                        # ^B T_C = ^B T_G @ ^G T_C
                        T_base_cam = T_gripper_base @ T_cam_gripper
                        R_base_cam = T_base_cam[:3, :3]
                        control_error_cam = error_in_cam_deadband * axis_mask
                        # æ­£åé¦ˆ/è´Ÿåé¦ˆåˆ†æï¼š
                        # - err_cam_z > 0 è¡¨ç¤º"å¤ªè¿œ"ï¼Œéœ€è¦ç›¸æœºå¾€å‰ (cam Z+)
                        # - R_base_cam æŠŠ cam Z+ æ˜ å°„åˆ° base æŸæ–¹å‘
                        # - æˆ‘ä»¬å¸Œæœ› gripper å¾€é‚£ä¸ªæ–¹å‘ç§»åŠ¨ï¼Œæ‰€ä»¥æ˜¯æ­£å·ï¼ˆåŒå‘ï¼‰
                        delta_base = R_base_cam @ control_error_cam
                    else:
                        # é™æ€æ˜ å°„ï¼ˆè°ƒè¯•ï¼‰ï¼šaxis_map + axis_sign
                        control_error_cam = error_in_cam_deadband * axis_mask * axis_sign
                        delta_base = np.zeros(3)
                        delta_base[axis_map[0]] += control_error_cam[0]
                        delta_base[axis_map[1]] += control_error_cam[1]
                        delta_base[axis_map[2]] += control_error_cam[2]
                    
                    # 3. è®¡ç®—æ§åˆ¶é‡
                    gain = 0.15  # å¢ç›Šï¼ˆåŠ å¤§ä»¥åŠ é€Ÿæ”¶æ•›ï¼‰
                    step_limit = 0.03 # é™å¹… (30mmï¼ŒåŠ å¤§ä»¥åŠ é€Ÿæ”¶æ•›)
                    
                    delta_base = delta_base * gain
                    
                    # é™å¹…
                    norm_delta = np.linalg.norm(delta_base)
                    if norm_delta > step_limit:
                        delta_base = delta_base / norm_delta * step_limit
                    
                    # --- è®¡ç®—å…³é”®è¾“å‡º ---
                    pos_target_base_mm = (T_target_base[:3, 3] * 1000.0)
                    pos_gripper_curr = T_gripper_base[:3, 3]
                    pos_gripper_des = pos_gripper_curr + delta_base
                    pos_gripper_des_mm = pos_gripper_des * 1000.0
                    
                    # è®¡ç®—å¤¹çˆªä¸ç›®æ ‡åœ¨Baseä¸‹çš„è¯¯å·®
                    error_base = pos_target_base_mm - pos_gripper_des_mm
                    
                    # ç®€åŒ–æ—¥å¿—è¾“å‡º
                    print(f"Target(Base): [{pos_target_base_mm[0]:7.1f}, {pos_target_base_mm[1]:7.1f}, {pos_target_base_mm[2]:7.1f}] mm | " +
                          f"PnP(Cam): [{pos_cam[0]:7.1f}, {pos_cam[1]:7.1f}, {pos_cam[2]:7.1f}] mm | " +
                          f"Gripperâ†’: [{pos_gripper_des_mm[0]:7.1f}, {pos_gripper_des_mm[1]:7.1f}, {pos_gripper_des_mm[2]:7.1f}] mm | " +
                          f"Error: [{error_base[0]:7.1f}, {error_base[1]:7.1f}, {error_base[2]:7.1f}] mm")

                    # æ˜¾ç¤ºæ˜ å°„æ¨¡å¼
                    cv2.putText(display, f"Mapping: {mapping_mode}", (10, 205), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

                    # --- ç®€åŒ–æ§åˆ¶: ç›´æ¥ç§»åŠ¨æœ«ç«¯ ---
                    # æ—¢ç„¶ T_cam_base_des = T_cam_base_curr + delta
                    # ä¸” Camera å’Œ Gripper åˆšæ€§è¿æ¥
                    # é‚£ä¹ˆ T_gripper_base_des = T_gripper_base_curr + delta
                    # è¿™æ ·å¯ä»¥é¿å… T_cam_gripper é€†çŸ©é˜µå¯èƒ½å¼•å…¥çš„è¯¯å·®
                    
                    # ä¿æŒæœ«ç«¯å§¿æ€ä¸å˜
                    R_gripper_des = T_gripper_base[:3, :3]
                    
                    T_gripper_base_des = np.eye(4)
                    T_gripper_base_des[:3, :3] = R_gripper_des
                    T_gripper_base_des[:3, 3] = pos_gripper_des
                    
                    # æ˜¾ç¤ºç›®æ ‡æœºæ¢°è‡‚ä½ç½®
                    cv2.putText(display, f"Gripper Target: [{pos_gripper_des[0]*1000:.0f}, {pos_gripper_des[1]*1000:.0f}, {pos_gripper_des[2]*1000:.0f}] mm", 
                               (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
                    
                    # IK æ±‚è§£
                    # å‚è€ƒ ik_solver_py.py çš„å‚æ•°é…ç½®
                    ik_res = calibrator.robot.ikine_LM(
                        T_gripper_base_des, 
                        q0=q_curr,
                        ilimit=300,  # å¢åŠ è¿­ä»£æ¬¡æ•°
                        slimit=3,    # å¢åŠ æœç´¢æ¬¡æ•°
                        tol=1e-2,     # æé«˜ç²¾åº¦è¦æ±‚
                        mask=np.array([1, 1, 1, 0.5, 0.5, 0]),
                        k=0.1,        # é˜»å°¼ç³»æ•°
                        method="sugihara" # ä½¿ç”¨ sugihara æ–¹æ³•
                    )
                    
                    if ik_res.success:
                        q_new = ik_res.q
                        
                        # å®‰å…¨æ£€æŸ¥: é˜²æ­¢å‰§çƒˆè¿åŠ¨
                        diff = np.linalg.norm(q_new - q_curr)
                        if diff > 1.5: # å¼§åº¦é˜ˆå€¼ (æ”¾å®½ä¸€ç‚¹)
                            cv2.putText(display, f"Movement too large: {diff:.2f}", (10, 90), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        else:
                            # æ‰§è¡Œè¿åŠ¨
                            # 1. å°†å¼§åº¦è½¬æ¢ä¸ºèˆµæœºæ­¥æ•°
                            targets = calibrator.robot.q_to_servo_targets(q_new)
                            # 2. å‘é€æ§åˆ¶æŒ‡ä»¤ (ä½¿ç”¨è¾ƒæ…¢çš„é€Ÿåº¦ä»¥ç¡®ä¿å®‰å…¨å’Œå¹³æ»‘)
                            calibrator.controller.fast_move_to_pose(targets, speed=200)
                            
                            if mapping_mode == "auto":
                                cv2.putText(display, "Tracking... AUTO", (10, 90), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                            else:
                                map_str = f"X->{axis_map[0]} Y->{axis_map[1]} Z->{axis_map[2]}"
                                cv2.putText(display, f"Tracking... Map:{map_str}", (10, 90), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    else:
                        cv2.putText(display, "IK Failed", (10, 90), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        print(f"âŒ IK Failed completely. Reason: {ik_res.reason}")
            
            else:
                stable_count = 0
                cv2.putText(display, "Target Lost", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # çŠ¶æ€æ˜¾ç¤º
            status = "FOLLOW ON" if following else "FOLLOW OFF (Press 'f')"
            color = (0, 255, 0) if following else (0, 255, 255)
            cv2.putText(display, status, (10, display.shape[0]-30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            cv2.imshow("Robot Tracking", display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('f'):
                following = not following
                print(f"Follow mode: {following}")
            elif key == ord('m'):
                mapping_mode = "manual" if mapping_mode == "auto" else "auto"
                print(f"Mapping mode: {mapping_mode}")
            elif key == ord('h'):
                print("Returning to home...")
                calibrator.controller.move_all_home()
                calibrator.controller.move_servo("gripper",3050)
                calibrator.controller.move_servo("wrist_roll",850)
                following = False
            # è°ƒè¯•æŒ‰é”®
            elif key == ord('1'):
                axis_mask[0] = 1.0 - axis_mask[0]
                print(f"Toggle Cam X axis: {axis_mask[0]}")
            elif key == ord('2'):
                axis_mask[1] = 1.0 - axis_mask[1]
                print(f"Toggle Cam Y axis: {axis_mask[1]}")
            elif key == ord('3'):
                axis_mask[2] = 1.0 - axis_mask[2]
                print(f"Toggle Cam Z axis: {axis_mask[2]}")
            elif key == ord('x'):
                axis_sign[0] *= -1
                print(f"Invert Cam X sign: {axis_sign[0]}")
            elif key == ord('y'):
                axis_sign[1] *= -1
                print(f"Invert Cam Y sign: {axis_sign[1]}")
            elif key == ord('z'):
                axis_sign[2] *= -1
                print(f"Invert Cam Z sign: {axis_sign[2]}")
            elif key == ord('7'):
                axis_map[0] = (axis_map[0] + 1) % 3
                print(f"Cam X maps to Base: {axis_map[0]}")
            elif key == ord('8'):
                axis_map[1] = (axis_map[1] + 1) % 3
                print(f"Cam Y maps to Base: {axis_map[1]}")
            elif key == ord('9'):
                axis_map[2] = (axis_map[2] + 1) % 3
                print(f"Cam Z maps to Base: {axis_map[2]}")

    except KeyboardInterrupt:
        pass
    finally:
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()

