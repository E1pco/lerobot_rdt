#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‹çœ¼æ ‡å®šæ•ˆæœæµ‹è¯•è„šæœ¬ - è§†è§‰è·Ÿéš
=====================================
åŠŸèƒ½:
  1. åŠ è½½æ‰‹çœ¼æ ‡å®šç»“æœ
  2. è¯†åˆ«æ£‹ç›˜æ ¼
  3. æ§åˆ¶æœºæ¢°è‡‚æœ«ç«¯è·Ÿéšæ£‹ç›˜æ ¼ (ä¿æŒå›ºå®šè·ç¦»å’Œå§¿æ€)

ä½¿ç”¨æ–¹æ³•:
  python vision/test_handeye_tracking.py
"""

import sys
import os
import cv2
import numpy as np
import time
from scipy.spatial.transform import Rotation as R

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from vision.handeye_calibration_eyeinhand import HandEyeCalibrator
from ik.robot import create_so101_5dof_gripper

def main():
    # 1. åŠ è½½æ ‡å®šç»“æœ
    calib_file = os.path.join(os.path.dirname(__file__), 'handeye_result.npy')
    if not os.path.exists(calib_file):
        print(f"âŒ æœªæ‰¾åˆ°æ ‡å®šæ–‡ä»¶: {calib_file}")
        return
    
    T_cam_gripper = np.load(calib_file)
    print(f"âœ… å·²åŠ è½½æ‰‹çœ¼æ ‡å®šå‚æ•° T_cam_gripper:\n{T_cam_gripper}")
    
    # 2. åˆå§‹åŒ– (å¤ç”¨ HandEyeCalibrator çš„åˆå§‹åŒ–é€»è¾‘)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦ä¿å­˜æ•°æ®ï¼Œåªæ˜¯åˆ©ç”¨å®ƒçš„æ£€æµ‹å’Œæœºå™¨äººæ§åˆ¶åŠŸèƒ½
    calibrator = HandEyeCalibrator(output_dir='/tmp')
    if not calibrator.init_robot():
        return

    # 3. æ§åˆ¶å¾ªç¯
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    print("\nğŸ¤– æœºå™¨äººè§†è§‰è·Ÿéšæµ‹è¯•")
    print("========================================")
    print("æŒ‰é”®è¯´æ˜:")
    print("  'f' - å¼€å¯/å…³é—­ è·Ÿéšæ¨¡å¼ (Follow)")
    print("  'h' - æœºæ¢°è‡‚å›ä¸­ (Home)")
    print("  'q' - é€€å‡º")
    print("========================================")
    
    following = False
    target_distance = 0.50  # ç›®æ ‡è·ç¦» 30cm
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret: break
            
            display = frame.copy()
            
            # æ£€æµ‹æ£‹ç›˜æ ¼
            success, T_target_cam, corners, err = calibrator.detect_chessboard(frame, refine_pose=True)
            
            if success:
                # ç»˜åˆ¶è§’ç‚¹
                cv2.drawChessboardCorners(display, calibrator.board_size, corners, True)
                # ç»˜åˆ¶åæ ‡è½´
                cv2.drawFrameAxes(display, calibrator.K, calibrator.dist, 
                                 T_target_cam[:3, :3], T_target_cam[:3, 3], 0.05)
                
                # --- æ ¸å¿ƒé€»è¾‘: è®¡ç®—ç›®æ ‡åœ¨åŸºåº§æ ‡ç³»ä¸‹çš„ä½å§¿ ---
                # 1. è·å–å½“å‰æœºæ¢°è‡‚ä½å§¿ T_gripper_base
                T_gripper_base, q_curr = calibrator.read_robot_pose(verbose=False)
                
                # 2. è®¡ç®—ç›®æ ‡åœ¨åŸºåº§æ ‡ç³»ä¸‹çš„ä½å§¿ T_target_base
                # é“¾å¼æ³•åˆ™: Base -> Gripper -> Camera -> Target
                T_target_base = T_gripper_base @ T_cam_gripper @ T_target_cam
                
                # æ˜¾ç¤ºç›®æ ‡åæ ‡
                pos_target = T_target_base[:3, 3] * 1000
                cv2.putText(display, f"Target (Base): [{pos_target[0]:.0f}, {pos_target[1]:.0f}, {pos_target[2]:.0f}] mm", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                if following:
                    # --- è§†è§‰ä¼ºæœæ§åˆ¶ (å¢é‡å¼ PBVS) ---
                    # åœ¨ç›¸æœºåæ ‡ç³»ä¸‹è®¡ç®—è¯¯å·®ï¼Œç„¶åè½¬æ¢åˆ°åŸºåº§æ ‡ç³»è¿›è¡Œç§»åŠ¨
                    # ç›®æ ‡: è®©æ£‹ç›˜æ ¼ä¸­å¿ƒä½äºç›¸æœºåæ ‡ç³»çš„ [0, 0, target_distance]
                    
                    # 1. è®¡ç®—ç›¸æœºåæ ‡ç³»ä¸‹çš„è¯¯å·®
                    # T_target_cam[:3, 3] æ˜¯ç›®æ ‡åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„å½“å‰ä½ç½® [x, y, z]
                    # æˆ‘ä»¬å¸Œæœ›å®ƒå˜æˆ [0, 0, target_distance]
                    target_pos_in_cam = T_target_cam[:3, 3]
                    desired_pos_in_cam = np.array([0, 0, target_distance])
                    
                    # è¯¯å·®å‘é‡ (ç›¸æœºéœ€è¦ç§»åŠ¨çš„æ–¹å‘)
                    # å¦‚æœç›®æ ‡åœ¨ç›¸æœºå³è¾¹ (x>0)ï¼Œç›¸æœºéœ€è¦å‘å³ç§»åŠ¨ (+x) æ‰èƒ½è¿½ä¸Š
                    # æ‰€ä»¥ error = target - desired
                    error_in_cam = target_pos_in_cam - desired_pos_in_cam
                    
                    # 2. å°†è¯¯å·®è½¬æ¢åˆ°åŸºåº§æ ‡ç³»
                    # T_cam_base = T_gripper_base @ T_cam_gripper
                    T_cam_base = T_gripper_base @ T_cam_gripper
                    R_cam_base = T_cam_base[:3, :3]
                    
                    error_in_base = R_cam_base @ error_in_cam
                    
                    # 3. è®¡ç®—æ–°çš„æœŸæœ›ç›¸æœºä½ç½® (å¢é‡å¼)
                    # ä½¿ç”¨æ¯”ä¾‹å¢ç›Š (Gain) æ§åˆ¶é€Ÿåº¦
                    gain = 0.1  # é™ä½å¢ç›Šä»¥æ›´å®‰å…¨
                    
                    # é™åˆ¶å•æ­¥æœ€å¤§ç§»åŠ¨é‡ (ä¾‹å¦‚ 2cm)ï¼Œé˜²æ­¢é£è½¦
                    step_limit = 0.02
                    
                    # è®¡ç®— Base ç³»ä¸‹çš„ä½ç§»å¢é‡
                    delta_base = gain * error_in_base
                    
                    # è°ƒè¯•æ‰“å°
                    print(f"Err(Cam): [{error_in_cam[0]*1000:.1f}, {error_in_cam[1]*1000:.1f}, {error_in_cam[2]*1000:.1f}] -> "
                          f"Delta(Base): [{delta_base[0]*1000:.1f}, {delta_base[1]*1000:.1f}, {delta_base[2]*1000:.1f}]")

                    # é™å¹…
                    norm_delta = np.linalg.norm(delta_base)
                    if norm_delta > step_limit:
                        delta_base = delta_base / norm_delta * step_limit
                    
                    pos_cam_curr = T_cam_base[:3, 3]
                    pos_cam_des = pos_cam_curr + delta_base
                    
                    # --- è°ƒè¯•: é”å®š Base Y è½´ ---
                    # ç”¨æˆ·åé¦ˆ Y è½´ä¸€ç›´æ¼‚ç§»ï¼Œå…ˆé”å®š Y è½´çœ‹ X å’Œ Z (è·ç¦») æ˜¯å¦æ­£å¸¸
                    # å¦‚æœ X/Z æ­£å¸¸ï¼Œè¯´æ˜æ˜¯ Y è½´æ–¹å‘åäº†æˆ–è€…æ ‡å®šæ—‹è½¬æœ‰è¯¯
                    # pos_cam_des[1] = pos_cam_curr[1] 
                    # æš‚æ—¶ä¸å®Œå…¨é”å®šï¼Œè€Œæ˜¯å°è¯•åè½¬ Y è½´çš„ä¿®æ­£æ–¹å‘ (å‡è®¾æ˜¯é•œåƒé—®é¢˜)
                    # å¦‚æœä¹‹å‰æ˜¯ "ä¸€ç›´å‘æ­£æ–¹å‘"ï¼Œè¯´æ˜æ˜¯æ­£åé¦ˆï¼Œæˆ‘ä»¬éœ€è¦è´Ÿåé¦ˆ
                    # Uncomment below to lock Y:
                    pos_cam_des[1] = pos_cam_curr[1]
                    
                    # 4. ä¿æŒå½“å‰å§¿æ€ (æš‚æ—¶ä¸æ—‹è½¬)
                    # è¿™æ ·å¯ä»¥é¿å… "LookAt" é€ æˆçš„æ—‹è½¬å‘æ•£é—®é¢˜
                    # å¦‚æœéœ€è¦æ—‹è½¬è·Ÿéšï¼Œå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šå¢åŠ æ—‹è½¬æ§åˆ¶
                    R_cam_des = R_cam_base 
                    
                    # æ„å»ºæœŸæœ›çš„ç›¸æœºä½å§¿çŸ©é˜µ
                    T_cam_base_des = np.eye(4)
                    T_cam_base_des[:3, :3] = R_cam_des
                    T_cam_base_des[:3, 3] = pos_cam_des
                    
                    # è®¡ç®—æœŸæœ›çš„æœ«ç«¯ä½å§¿ T_gripper_base_des
                    # T_gripper_base = T_cam_base * inv(T_cam_gripper)
                    T_gripper_base_des = T_cam_base_des @ np.linalg.inv(T_cam_gripper)
                    
                    print(f"Err(Cam): {error_in_cam*1000} mm -> Err(Base): {error_in_base*1000} mm")
                    print(f"Desired Gripper Pos (Base): {T_gripper_base_des[:3,3]*1000}")
                    # IK æ±‚è§£
                    # å‚è€ƒ ik_solver_py.py çš„å‚æ•°é…ç½®
                    ik_res = calibrator.robot.ikine_LM(
                        T_gripper_base_des, 
                        q0=q_curr,
                        ilimit=300,  # å¢åŠ è¿­ä»£æ¬¡æ•°
                        slimit=3,    # å¢åŠ æœç´¢æ¬¡æ•°
                        tol=1e-2,     # æé«˜ç²¾åº¦è¦æ±‚
                        mask=np.array([1, 1, 1, 0.5, 0.5, 0]),
                        k=0.1,        # é˜»å°¼ç³»æ•°
                        method="sugihara" # ä½¿ç”¨ sugihara æ–¹æ³•
                    )
                    
                    if not ik_res.success:
                        # å¤±è´¥å°è¯•: ä»…ä½ç½® (å¿½ç•¥æ‰€æœ‰æ—‹è½¬)
                        print(f"âš ï¸ IK (Pos+Rot) failed: {ik_res.reason}. Trying Pos only...")
                        ik_res = calibrator.robot.ikine_LM(
                            T_gripper_base_des, 
                            q0=q_curr,
                            ilimit=300, 
                            slimit=3,
                            tol=1e-3,
                            mask=np.array([1, 1, 1, 0.8, 0.8, 0]),
                            k=0.1,
                            method="sugihara"
                        )
                    
                    if ik_res.success:
                        q_new = ik_res.q
                        
                        # å®‰å…¨æ£€æŸ¥: é˜²æ­¢å‰§çƒˆè¿åŠ¨
                        diff = np.linalg.norm(q_new - q_curr)
                        if diff > 1.5: # å¼§åº¦é˜ˆå€¼ (æ”¾å®½ä¸€ç‚¹)
                            cv2.putText(display, f"Movement too large: {diff:.2f}", (10, 60), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        else:
                            # æ‰§è¡Œè¿åŠ¨
                            # 1. å°†å¼§åº¦è½¬æ¢ä¸ºèˆµæœºæ­¥æ•°
                            targets = calibrator.robot.q_to_servo_targets(q_new)
                            # 2. å‘é€æ§åˆ¶æŒ‡ä»¤ (ä½¿ç”¨è¾ƒæ…¢çš„é€Ÿåº¦ä»¥ç¡®ä¿å®‰å…¨å’Œå¹³æ»‘)
                            calibrator.controller.fast_move_to_pose(targets, speed=200)
                            
                            cv2.putText(display, "Tracking...", (10, 60), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    else:
                        cv2.putText(display, "IK Failed", (10, 60), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                        print(f"âŒ IK Failed completely. Reason: {ik_res.reason}")
            
            else:
                cv2.putText(display, "Target Lost", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # çŠ¶æ€æ˜¾ç¤º
            status = "FOLLOW ON" if following else "FOLLOW OFF (Press 'f')"
            color = (0, 255, 0) if following else (0, 255, 255)
            cv2.putText(display, status, (10, display.shape[0]-30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            cv2.imshow("Robot Tracking", display)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('f'):
                following = not following
                print(f"è·Ÿéšæ¨¡å¼: {'å¼€å¯' if following else 'å…³é—­'}")
            elif key == ord('h'):
                print("å›ä¸­...")
                calibrator.controller.move_all_home()
                following = False

    except KeyboardInterrupt:
        pass
    finally:
        calibrator.close()
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
